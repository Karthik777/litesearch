{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "---\n",
    "description: Building blocks for litesearch\n",
    "output-file: index.html\n",
    "title: core\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introduction\n",
    "We often have to go through a whole bunch of hoops to get documents processed and ready for searching through them.\n",
    "`litesearch` plans to make this as easy as possible by providing simple building blocks to set up a database with FTS5 and vector search capabilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp core"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "from fastcore.all import first, dict2obj, L, Path, Generator\n",
    "from fastlite import Database, patch, Optional, Union, Iterable\n",
    "from apswutils.utils import cursor_row2dict\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "@patch\n",
    "def query(self: Database, sql: str, params: Optional[Union[Iterable, dict]] = None) -> Generator[dict, None, None]:\n",
    "    '''Execute a query and return results as a list of AttrDict'''\n",
    "    p = params if isinstance(params, dict) else tuple(params or tuple())\n",
    "    cursor = self.execute(sql, p)\n",
    "    cursor.row_trace = cursor_row2dict\n",
    "    yield from cursor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Simple Docs table setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "@patch\n",
    "def get_store(self:Database,    # database connection\n",
    "            name:str='store',   # table name\n",
    "            hash:bool=False,    # whether to create hash index on content\n",
    "            **kw,               # additional args to pass to fastlite create\n",
    "):\n",
    "    \"Make a sql table for content storage with FTS5 and vector search capabilities\"\n",
    "    cols = dict(content=str, embedding=bytes, metadata=str, uploaded_at=float,defaults=dict(uploaded_at='CURRENT_TIMESTAMP'),pk='id')\n",
    "    if hash: cols.update(dict(hash_id='id',hash_id_columns=['content']))\n",
    "    else: cols.update(dict(id=int, not_null=['content']))\n",
    "    _content = self.t[name].create(**cols,if_not_exists=True, **kw)\n",
    "    if not _content.detect_fts(): _content.enable_fts(['content','metadata'], create_triggers=True, tokenize='porter', replace=True)\n",
    "    return _content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def database(pth_or_uri:str=':memory:',     # the database name or URL\n",
    "             wal:bool=True,                 # use WAL mode\n",
    "             sem_search:bool=True,          # enable usearch extensions\n",
    "             **kw,                          # additional args to pass to apswutils database\n",
    "             ) -> Database:\n",
    "    'Set up a database connection and load usearch extensions.'\n",
    "\n",
    "    if isinstance(pth_or_uri, (str, Path)): Path(pth_or_uri).parent.mkdir(exist_ok=True)\n",
    "    _db = Database(pth_or_uri, **kw)\n",
    "    if wal: _db.enable_wal()\n",
    "    if not sem_search: return _db\n",
    "    from usearch import sqlite_path\n",
    "    _db.conn.enableloadextension(True)\n",
    "    _db.conn.loadextension(sqlite_path())\n",
    "    _db.conn.enableloadextension(False)\n",
    "    return _db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "@patch\n",
    "def search(self: Database,  # database connection\n",
    "           q:str,  # query string\n",
    "           emb:bytes,  # embedding vector\n",
    "           columns:list=None,  # columns to return\n",
    "           where:str=None,  # additional where clause\n",
    "           where_args:dict=None,  # args for where clause\n",
    "           limit:int|None=50,  # limit on number of results\n",
    "           offset:int|None=None,  # offset for results\n",
    "           table_name='store',  # table name\n",
    "           emb_col='embedding',  # embedding column name\n",
    "           emb_metric:str='cosine',  # embedding distance metric (cosine,sqeuclidean,inner,divergence)\n",
    "           rrf=True,  # need to rerank results with reciprocal rank fusion\n",
    "           dtype=np.float16,  # embedding dtype\n",
    "           ):\n",
    "    'Search the litesearch store with fts and vector search combined.'\n",
    "    if not q.strip(): return None\n",
    "    content = self.get_store(table_name)\n",
    "    if not columns: columns = ['content', 'metadata', 'embedding']\n",
    "    fts = content.search(q, order_by='rank', columns=columns, limit=limit, where=where, where_args=where_args, quote=True)\n",
    "    df='i8' if dtype==np.int8 else 'f16' if dtype==np.float16 else 'f64' if dtype==np.float64 else 'f32'\n",
    "    vecs = content(select=','.join(columns), where=f'{emb_col} is not null' + (' AND ' + where if where else ''),\n",
    "        where_args=dict(qvec=emb, **(where_args or {})), order_by=f'distance_{emb_metric}_{df}({emb_col}, :qvec)', limit=limit, offset=offset)\n",
    "    if not rrf: return dict(fts=[f for f in fts], vec=vecs)\n",
    "    ranked = (dict2obj(L(fts)) + L(dict2obj(vecs))).groupby('content')\n",
    "    return [first(kv[1]) for kv in ranked.items()][:limit]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "Let's test it out. We will create a database, run embedding comparisons, create a store and run search"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "db = database()"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "The fastlite database is set up with usearch extensions. Let's run some distance calculations."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'sqeuclidean_v1_v2': 100.0, 'sqeuclidean_v1_v3': 56.25, 'sqeuclidean_v2_v3': 6.25}]\n",
      "[{'divergence_v1_v2': 34.657352447509766, 'divergence_v1_v3': 12.046551704406738, 'divergence_v2_v3': 8.66433334350586}]\n",
      "[{'inner_v1_v2': 1.0, 'inner_v1_v3': -24.0, 'inner_v2_v3': 1.0}]\n",
      "[{'cosine_v1_v2': 1.0, 'cosine_v1_v3': 0.0, 'cosine_v2_v3': 1.0}]\n"
     ]
    }
   ],
   "source": [
    "embs = dict(\n",
    "\tv1=np.ones((100,),dtype=np.float32).tobytes(), \t\t# vector of ones\n",
    "\tv2=np.zeros((100,),dtype=np.float32).tobytes(), \t# vector of zeros\n",
    "\tv3=np.full((100,),0.25,dtype=np.float32).tobytes() \t# vector of 0.25s\n",
    ")\n",
    "def dist_q(metric):\n",
    "\treturn db.q(f'''\n",
    "\t\tselect\n",
    "\t\t\tdistance_{metric}_f32(:v1,:v2) as {metric}_v1_v2,\n",
    "\t\t\tdistance_{metric}_f32(:v1,:v3) as {metric}_v1_v3,\n",
    "\t\t\tdistance_{metric}_f32(:v2,:v3) as {metric}_v2_v3\n",
    "\t''', embs)\n",
    "\n",
    "for fn in ['sqeuclidean', 'divergence', 'inner', 'cosine']: print(dist_q(fn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "store is created\n",
      "detected fts table:  store_fts\n",
      "Search results: 0\n"
     ]
    }
   ],
   "source": [
    "db.get_store()\n",
    "if 'store' in db.t: print('store is created')\n",
    "print('detected fts table: ',db.t.store.detect_fts())\n",
    "print('Search results:', len(db.search('h',np.zeros((100,)).tobytes()))) # there is no data yet, so should be 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "We can also create a store with hash index on content. Useful for code search applications"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'id': '250ce2bffa97ab21fa9ab2922d19993454a0cf28', 'content': 'hello world'},\n",
       " {'id': 'c89f43361891bfab9290bcebf182fa5978f89700', 'content': 'hi there'},\n",
       " {'id': '882293d5e5c3d3e04e8e0c4f7c01efba904d0932', 'content': 'goodbye now'}]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "st=db.get_store(name='my_store', hash=True)\n",
    "st.insert_all([dict(content='hello world', embedding=np.ones((100,),dtype=np.float16).tobytes()),\n",
    "                           dict(content='hi there', embedding=np.full((100,),0.5,dtype=np.float16).tobytes()),\n",
    "                           dict(content='goodbye now', embedding=np.zeros((100,),dtype=np.float16).tobytes())],upsert=True,hash_id='id')\n",
    "st(select='id,content')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "Let's run a search again."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'fts': [{'content': 'hello world'}],\n",
       " 'vec': [{'content': 'hello world'}, {'content': 'hi there'}]}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": "db.search(q='hello', emb=np.full((100,),0.25, dtype=np.float16).tobytes(), columns=['content'], table_name='my_store',limit=2, rrf=False)"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "Now, let's try the same but with a broader query."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'content': 'goodbye now'}, {'content': 'hello world'}]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": "db.search(q='goodbye OR hi', emb=np.full((100,),0,dtype=np.float16).tobytes(), columns=['content'], table_name='my_store',limit=2)"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "You can use different kind of embedding metrics as well. The default is `cosine`. Let's try with `divergence` distance"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'content': 'goodbye now'}, {'content': 'hi there'}]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": "db.search(q='goodbye OR hi', emb=np.full((100,),0,dtype=np.float16).tobytes(), columns=['content'], table_name='my_store',limit=2, emb_metric='divergence')"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "import nbdev; nbdev.nbdev_export()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
