{
 "cells": [
  {
   "cell_type": "raw",
   "id": "dca3da88c5c8a1e7",
   "metadata": {},
   "source": [
    "---\n",
    "description: some utilities to aid data extraction and query preprocessing\n",
    "output-file: index.html\n",
    "title: data\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cd2cae8a5079bb4",
   "metadata": {},
   "source": [
    "We will build a simple ingestion pipeline to ingest pdf documents into litesearch database for searching."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b58f453150128627",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a1e955269e0d234",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "from fastcore.all import L, concat, patch, ifnone, Path, delegates, globtastic, parallel, type2str\n",
    "from pymupdf import Document, Pixmap, csRGB, Page"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc921b66a39a49da",
   "metadata": {},
   "source": "Extensions to pymupdf Document and Page classes to extract texts, images and links"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc014ece1162af13",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "@patch\n",
    "def get_texts(self: Document, st=0, end=-1, **kw):\n",
    "\treturn L(self[st:end]).map(lambda p: p.get_text(**kw))\n",
    "\n",
    "@patch\n",
    "def get_links(self: Document, st=0, end=-1):\n",
    "\treturn L(self[st:end]).map(lambda p: p.get_links()).concat()\n",
    "\n",
    "@patch\n",
    "def ext_im(self: Document, it=None):\n",
    "    if not it: return None\n",
    "    assert isinstance(it, tuple) and len(it) > 2, 'Invalid image tuple'\n",
    "    xref, smask = it[0], it[1]\n",
    "    if smask > 0:\n",
    "        pix0 = Pixmap(self.extract_image(xref)['image'])\n",
    "        if pix0.alpha: pix0 = Pixmap(pix0, 0)  # remove alpha channel\n",
    "        mask = Pixmap(self.extract_image(smask)['image'])\n",
    "        try: pix = Pixmap(pix0, mask)\n",
    "        except: pix = Pixmap(self.extract_image(xref)['image'])\n",
    "        ext = 'pam' if pix0.n > 3 else 'png'\n",
    "        return dict(ext=ext, colorspace=pix.colorspace.n, image=pix.tobytes(ext))\n",
    "    if '/ColorSpace' in self.xref_object(xref, compressed=True):\n",
    "        pix = Pixmap(csRGB, Pixmap(self, xref))\n",
    "        return dict(ext='png', colorspace=3, image=pix.tobytes('png'))\n",
    "    return self.extract_image(xref)\n",
    "\n",
    "@patch\n",
    "def ext_imgs(self: Document, st=0, end=-1):\n",
    "\tf = lambda p: [ext_im(self,it) for it in p.get_images(full=True)]\n",
    "\treturn L(self[st:end]).map(f).concat()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca87728a17910e0",
   "metadata": {},
   "source": "Code extraction utilities"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d62e37b470a1055",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def pyparse(p:Path=None,    # path to a python file\n",
    "            code:str=None,  # code string to parse\n",
    "            imports=False   # include import statements as code chunks\n",
    ") -> L:\n",
    "    'Parse a code string or python file and return code chunks as list of dicts with content and metadata.'\n",
    "    assert bool(code) ^ bool(p), 'Either code or p must be provided, not both.'\n",
    "    if not code: code = Path(p).read_text(encoding='utf-8')\n",
    "    import ast\n",
    "    from ast import get_source_segment as gs\n",
    "    tree=ast.parse(code)\n",
    "    [setattr(c,'parent',n) for n in ast.walk(tree) for c in ast.iter_child_nodes(n)]\n",
    "    def meta(xtra=None): return dict(path=p,uploaded_at=Path(p).stat().st_mtime if p else None,**ifnone(xtra, {}))\n",
    "    def n2c(n): return dict(content=gs(code, n).strip(), metadata=meta(dict(name=getattr(n,'name',None), type=type2str(n.__class__), lineno=getattr(n,'lineno',None), end_lineno=getattr(n,'end_lineno',None))))\n",
    "    def is_mod(n): return isinstance(n, (ast.FunctionDef, ast.AsyncFunctionDef, ast.ClassDef))\n",
    "    def is_assign(n): return isinstance(n, (ast.Assign, ast.AnnAssign)) and n.value\n",
    "    def is_p_mod(n): return getattr(getattr(n,'parent',None),'__class__',None) == ast.Module\n",
    "    def is_allowed(n): return is_p_mod(n) and (is_mod(n) or is_assign(n) or (imports and isinstance(n, ast.ImportFrom)))\n",
    "    return L(ast.walk(tree)).filter(is_allowed).map(n2c)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfee1f80ee97c56c",
   "metadata": {},
   "source": "You can use `pyparse` to extract code chunks from a python file or code string."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "247cd41484e9bf5d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(#2) [{'content': 'a=1', 'metadata': {'path': None, 'uploaded_at': None, 'name': None, 'type': 'Assign', 'lineno': 3, 'end_lineno': 3}},{'content': 'class SomeClass:\\n    def __init__(self,x): store_attr()\\n    def method(self): return self.x + a', 'metadata': {'path': None, 'uploaded_at': None, 'name': 'SomeClass', 'type': 'ClassDef', 'lineno': 4, 'end_lineno': 6}}]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "txt = \"\"\"\n",
    "from fastcore.all import *\n",
    "a=1\n",
    "class SomeClass:\n",
    "    def __init__(self,x): store_attr()\n",
    "    def method(self): return self.x + a\n",
    " \"\"\"\n",
    "pyparse(code=txt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8deea5cb14904a64",
   "metadata": {},
   "source": "Setting imports to True will also include import statements as code chunks."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6032f8cdd0f6a5dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(#3) [{'content': 'from fastcore.all import *', 'metadata': {'path': None, 'uploaded_at': None, 'name': None, 'type': 'ImportFrom', 'lineno': 2, 'end_lineno': 2}},{'content': 'a=1', 'metadata': {'path': None, 'uploaded_at': None, 'name': None, 'type': 'Assign', 'lineno': 3, 'end_lineno': 3}},{'content': 'class SomeClass:\\n    def __init__(self,x): store_attr()\\n    def method(self): return self.x + a', 'metadata': {'path': None, 'uploaded_at': None, 'name': 'SomeClass', 'type': 'ClassDef', 'lineno': 4, 'end_lineno': 6}}]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": "pyparse(code=txt, imports=True)"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55c525653e25a703",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "py_dir_skip_re=r'(^tests?$|^__pycache__$|^\\.eggs$|^\\.mypy_cache$|^\\.tox$|^examples?$|^docs?$|^build$|^dist$|^\\.git$|^\\.ipynb_checkpoints$)'\n",
    "py_file_skip_re=r'(^__init__\\.py$|^setup\\.py$|^conftest\\.py$|^test_.*\\.py$|^tests?\\.py$|^.*_test\\.py$)'\n",
    "py_glob, skip_py_glob = '*.py', '_*'\n",
    "\n",
    "@delegates(globtastic)\n",
    "def pkg2files(pkg:str,\t\t\t\t\t\t\t\t# package name\n",
    "              file_glob:str=py_glob,\t\t\t\t# file glob to match\n",
    "              skip_file_glob:str=skip_py_glob,\t\t# file glob to skip\n",
    "              skip_file_re=py_file_skip_re, \t\t# regex to skip files\n",
    "              skip_folder_re=py_dir_skip_re, \t\t# regex to skip folders\n",
    "\t\t\t  **kwargs\t\t\t\t\t\t\t\t# additional args to pass to globtastic\n",
    ")->L:\n",
    "\t'Return list of python files in a package excluding tests and setup files.'\n",
    "\tfrom importlib.util import find_spec as fs\n",
    "\tif not fs(pkg): return L()\n",
    "\treturn globtastic(Path(fs(pkg).origin).parent,file_glob=file_glob,skip_file_glob=skip_file_glob,\n",
    "\t\tfolder_re=pkg, skip_folder_re=skip_folder_re, skip_file_re=skip_file_re, **kwargs)\n",
    "\n",
    "def pkg2chunks(pkg:str,             # package name\n",
    "               imports:bool=False,  # include import statements as code chunks\n",
    "               **kw                 # additional args to pass to pkg2files\n",
    ")->L:\n",
    "    'Return code chunks from a package with extra metadata.'\n",
    "    from importlib.metadata import version\n",
    "    upd_v = lambda d: d['metadata'].update(dict(package=pkg, version=version(pkg)))\n",
    "    return parallel(pyparse, pkg2files(pkg,**kw), imports=imports).concat().map(lambda d: upd_v(d) or d)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8aa2409826c24cc7",
   "metadata": {},
   "source": "`pkg2chunks` can be used to extract code chunks from an entire package installed in your environment."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5d11d63a9064644",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'content': 'def t(self:Database): return _TablesGetter(self)',\n",
       " 'metadata': {'path': '/Users/71293/code/litesearch/.venv/lib/python3.13/site-packages/fastlite/core.py',\n",
       "  'uploaded_at': 1752468812.9739048,\n",
       "  'name': 't',\n",
       "  'type': 'FunctionDef',\n",
       "  'lineno': 44,\n",
       "  'end_lineno': 44,\n",
       "  'package': 'fastlite',\n",
       "  'version': '0.2.1'}}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chunks=pkg2chunks('fastlite')\n",
    "chunks.filter(lambda d: d['metadata']['type']=='FunctionDef')[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7652cb1d1f39fadc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def installed_packages(nms:list=None # list of package names\n",
    ")->L:\n",
    "    'Return list of installed packages. If nms is provided, return only those packages.'\n",
    "    from importlib.util import find_spec as fs\n",
    "    from importlib.metadata import distributions as dists, distribution as dist\n",
    "    not_stdlib = lambda d: d.metadata.get('Author-email') not in ('Python', None)\n",
    "    pkgs = L(nms).filter(fs).map(dist) if nms else L(dists())\n",
    "    return pkgs.filter(not_stdlib).map(lambda d: d.metadata['Name'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a2ab99dcc8f618c",
   "metadata": {},
   "source": "Get list of installed packages in your environment using `installed_packages`. If you pass a list of package names, it only returns them if they exist in your environment."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbd69169413736e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(#179) ['litesearch','shellingham','jiter','ipykernel','simsimd','threadpoolctl','coloredlogs','uri-template','humanfriendly','socksio','rfc3339-validator','pexpect','jupyterlab-quarto','fqdn','requests','babel','rich','traitlets','tokenizers','urllib3'...]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "installed_packages(['fstlite']) # non existent package\n",
    "installed_packages(['fastlite']) # existing package\n",
    "installed_packages() # all installed packages that are not stdlib"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97191acf7ca88c05",
   "metadata": {},
   "source": "Query Preprocessing utilities"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f887a2d1e48c7e1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def clean(q:str  # query to be passed for fts search\n",
    "          ):\n",
    "    '''Clean the query by removing * and returning None for empty queries.'''\n",
    "    return q.replace('*', '') if q.strip() else None\n",
    "\n",
    "def add_wc(q:str  # query to be passed for fts search\n",
    "           ):\n",
    "    '''Add wild card * to each word in the query.'''\n",
    "    return ' '.join(map(lambda w: w + '*', q.split(' ')))\n",
    "\n",
    "def mk_wider(q:str  # query to be passed for fts search\n",
    "             ):\n",
    "    '''Widen the query by joining words with OR operator.'''\n",
    "    return ' OR '.join(map(lambda w: f'{w}', q.split(' ')))\n",
    "\n",
    "def kw(q:str  # query to be passed for fts search\n",
    "       ):\n",
    "    '''Extract keywords from the query using YAKE library.'''\n",
    "    from yake import KeywordExtractor as KW\n",
    "    return ' '.join((set(concat([k.split(' ') for k, s in KW().extract_keywords(q)]))))\n",
    "\n",
    "def pre(q:str,          # query to be passed for fts search\n",
    "        wc=True,        # add wild card to each word\n",
    "        wide=True,      # widen the query with OR operator\n",
    "        extract_kw=True # extract keywords from the query\n",
    "        ):\n",
    "    '''Preprocess the query for fts search.'''\n",
    "    q = clean(q)\n",
    "    if not q.strip(): return ''\n",
    "    if extract_kw: q = kw(q)\n",
    "    if wc: q = add_wc(q)\n",
    "    if wide: q = mk_wider(q)\n",
    "    return q"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c45d89b74a9d2b5",
   "metadata": {},
   "source": "You can clean queries passed into fts search using `clean`, add wild cards using `add_wc`, widen the query using `mk_wider` and extract keywords using `kw`. You can combine all these using `pre` function."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad20548e6fca145",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preprocessed q with defaults: `query* OR sample*`\n",
      "keywords extracted: `query sample`\n",
      "q with wild card: `This* is* a* sample* query*`\n"
     ]
    }
   ],
   "source": [
    "q = 'This is a sample query'\n",
    "print('preprocessed q with defaults: `%s`' %pre(q))\n",
    "print('keywords extracted: `%s`' %pre(q, wc=False, wide=False))\n",
    "print('q with wild card: `%s`' %pre(q, extract_kw=False, wide=False, wc=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaf6852b35d08be8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "import nbdev; nbdev.nbdev_export()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
