{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Simple RAG with litesearch\n",
    "> We will build a simple rag with litesearch. Do not be deceived. We are doing a whole bunch of heavylifting under the hood with very little code."
   ],
   "id": "94f1234b99572d4e"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-10T00:11:52.041300Z",
     "start_time": "2025-11-10T00:11:51.750508Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#| export\n",
    "from fastcore.all import *\n",
    "from fastlite import *\n",
    "import numpy as np\n",
    "import re\n",
    "from selectolax.parser import HTMLParser\n",
    "from litesearch import *"
   ],
   "id": "3edd79a6c9ca938",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Let's set the db up. This db has usearch loaded. So, you can run cosine distance calculations using simd(means fast, real fast)",
   "id": "5e79b20a43980d79"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-10T00:11:53.547732Z",
     "start_time": "2025-11-10T00:11:53.538851Z"
    }
   },
   "cell_type": "code",
   "source": "db:Database=setup_db('breugel.db')",
   "id": "41c065b00f3db9a1",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-10T00:11:54.721064Z",
     "start_time": "2025-11-10T00:11:54.716341Z"
    }
   },
   "cell_type": "code",
   "source": "db.q('select distance_cosine_f16(:vec1,:vec2)', dict(vec1=np.ones(512, np.float16).tobytes(), vec2=np.zeros(512, np.float16).tobytes()))",
   "id": "7e0193d25606a505",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'distance_cosine_f16(:vec1,:vec2)': 1.0}]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "There are way more functions you can run now. Checkout: https://unum-cloud.github.io/USearch/sqlite/index.html",
   "id": "9a1b93c61a890038"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "#### Ingest PDF documents\n",
    "> We will ingest a sample PDF documents from Bruegel. We will restrict it to 10 pdfs. But it has about 1800 in total. This isto showcase real world utilities of litesearch.\n",
    "> We will read the PDF document using `read_pdf` function from litesearch.ingest module.\n",
    "> We will then scrape the urls from the pdf and then recursively get all pdf's off of those links and ingest them as well.'"
   ],
   "id": "bbe74532d19fe55b"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-10T00:11:57.590328Z",
     "start_time": "2025-11-10T00:11:57.580621Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#| export\n",
    "class BruegelDataset:\n",
    "    ''' Dataset for Bruegel PDF documents.'''\n",
    "    URL = 'https://www.bruegel.org/system/files/2024-06/Bruegel_factsheet_2024_0.pdf'\n",
    "    URI_SCHEMA = r'^http://data\\.europa\\.eu/eli/(?P<typedoc>[^/]+)/(?P<year>\\d{4})/(?P<natural_number>\\d+)/(?P<date>\\d{4}-\\d{2}-\\d{2})/(?P<lang>[a-z]{2,3})/pdfa2a$'\n",
    "    def __init__(self, dest:Path=Path('bruegel_dataset')):\n",
    "        self.dest = dest\n",
    "        self.pdfs = self()\n",
    "\n",
    "\n",
    "    @staticmethod\n",
    "    def _is_pdf_link(l:str): return l.strip() and (l.lower().endswith('.pdf') or 'pdf' in l.lower())\n",
    "    @staticmethod\n",
    "    def url2name(url: str) -> str | None:\n",
    "        if re.match(BruegelDataset.URI_SCHEMA, url):\n",
    "            m = re.match(BruegelDataset.URI_SCHEMA, url)\n",
    "            return f\"{m['typedoc']}_{m['year']}_{m['natural_number']}_{m['date']}_{m['lang']}.pdf\"\n",
    "        return url.split('/')[-1] if url.split('/')[-1] != '' else url.rstrip('/').split('/')[-1]+'.html'\n",
    "\n",
    "    def _get_meta(self, r):\n",
    "        try:\n",
    "            meta = HTMLParser(r).tags('meta')\n",
    "            nodes = L([dict2obj(m.attributes) for m in meta]).filter(\n",
    "                lambda m: 'about' in m\n",
    "            ).filter(\n",
    "                lambda m: ('property' in m and m['property'].lower() in ['eli:is_embodied_by','eli:title'])\n",
    "            ).filter(\n",
    "                lambda m: ('resource' in m and 'pdfa2a' in m['resource'].lower()) or 'content' in m\n",
    "            ).groupby('about')\n",
    "            for k in nodes: nodes[k] = merge(*nodes[k])\n",
    "            return L([(nodes[n]['resource'], nodes[n]['content']) for n in nodes])\n",
    "        except: pass\n",
    "\n",
    "\n",
    "    def read_link(self, l, dest=None):\n",
    "        try:\n",
    "\t        p = self.save_pdf(l, dest)\n",
    "\t        return p.read_text()\n",
    "        except: return ''\n",
    "\n",
    "    def save_pdf(self, l:str, dest:Path=None) -> Path | None:\n",
    "        try:\n",
    "            if not l : return None\n",
    "            if not dest: dest = self.dest\n",
    "            p = dest / self.url2name(l)\n",
    "            if not (p.exists() and p.stat().st_size > 1024): p = urlsave(l,p)\n",
    "            return p\n",
    "        except Exception as ex: print(ex); return None\n",
    "\n",
    "    def __call__(self, sample_size=10) -> L:\n",
    "        '''Make a dataset of documents from a pdf url and all linked pdfs.'''\n",
    "\n",
    "        def get_linked_pdfs(doc, filter=True):\n",
    "            links = doc.pages.map(lambda p: p.links.map(lambda l: l.uri)).concat().unique()\n",
    "            if filter: links = links.filter(self._is_pdf_link)\n",
    "            return links[:sample_size]\n",
    "\n",
    "        pth = self.dest / self.url2name(self.URL)\n",
    "        if not pth.exists(): pth = urlsave(self.URL, self.dest / self.url2name(self.URL))\n",
    "        main_doc = read_pdf(pth)\n",
    "        pdf_lp = Path(self.dest / 'pdf_links1')\n",
    "        if not pdf_lp.exists():\n",
    "            links = get_linked_pdfs(main_doc, filter=False)\n",
    "            print(f'Found {len(links)} linked pdfs.')\n",
    "            all_c = parallel(self.read_link, links, threadpool=True, dest=self.dest/'links')\n",
    "            pdf_links = parallel(self._get_meta, all_c, threadpool=True).concat().unique()\n",
    "            print(f'Found {len(pdf_links)} external pdf links.')\n",
    "            pdf_lp.mk_write('\\n'.join([f'{l[0]},{l[1]}' for l in pdf_links]))\n",
    "        pdf_subset = pdf_lp.readlines()[:sample_size]\n",
    "        url2tit = {l.split(',')[0]: l.split(',')[1] for l in pdf_subset}\n",
    "        pdf_list = L([l.split(',')[0] for l in pdf_subset])\n",
    "        name2url = {self.url2name(l): l for l in pdf_list}\n",
    "        pdf_set = set(pdf_list.map(self.url2name))\n",
    "        downloaded_pdfs = globtastic(self.dest / 'pdfs', file_glob='*.pdf', func=Path).filter(lambda m: m.stat().st_size > 1024).map(lambda p: p.name)\n",
    "        fetch_list = [name2url.get(d) for d in pdf_set.difference(downloaded_pdfs)]\n",
    "        if fetch_list:\n",
    "            print(f'Downloading {len(fetch_list)} new pdfs...')\n",
    "            parallel(self.save_pdf, fetch_list, dest=self.dest/'pdfs')\n",
    "        return globtastic(self.dest / 'pdfs', file_glob='*.pdf', func=Path).filter(lambda m: m.name in name2url).map(lambda m: AttrDict(path=m, title=url2tit[name2url[m.name]]))"
   ],
   "id": "fe6fbcae5619ee36",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-10T00:17:28.620428Z",
     "start_time": "2025-11-10T00:12:10.265232Z"
    }
   },
   "cell_type": "code",
   "source": "b = BruegelDataset()",
   "id": "efb14b2e333b565d",
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mKeyboardInterrupt\u001B[39m                         Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[5]\u001B[39m\u001B[32m, line 1\u001B[39m\n\u001B[32m----> \u001B[39m\u001B[32m1\u001B[39m b = \u001B[43mBruegelDataset\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[4]\u001B[39m\u001B[32m, line 8\u001B[39m, in \u001B[36mBruegelDataset.__init__\u001B[39m\u001B[34m(self, dest)\u001B[39m\n\u001B[32m      6\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34m__init__\u001B[39m(\u001B[38;5;28mself\u001B[39m, dest:Path=Path(\u001B[33m'\u001B[39m\u001B[33mbruegel_dataset\u001B[39m\u001B[33m'\u001B[39m)):\n\u001B[32m      7\u001B[39m     \u001B[38;5;28mself\u001B[39m.dest = dest\n\u001B[32m----> \u001B[39m\u001B[32m8\u001B[39m     \u001B[38;5;28mself\u001B[39m.pdfs = \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[4]\u001B[39m\u001B[32m, line 63\u001B[39m, in \u001B[36mBruegelDataset.__call__\u001B[39m\u001B[34m(self, sample_size)\u001B[39m\n\u001B[32m     61\u001B[39m pdf_lp = Path(\u001B[38;5;28mself\u001B[39m.dest / \u001B[33m'\u001B[39m\u001B[33mpdf_links1\u001B[39m\u001B[33m'\u001B[39m)\n\u001B[32m     62\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m pdf_lp.exists():\n\u001B[32m---> \u001B[39m\u001B[32m63\u001B[39m     links = \u001B[43mget_linked_pdfs\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmain_doc\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mfilter\u001B[39;49m\u001B[43m=\u001B[49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m)\u001B[49m\n\u001B[32m     64\u001B[39m     \u001B[38;5;28mprint\u001B[39m(\u001B[33mf\u001B[39m\u001B[33m'\u001B[39m\u001B[33mFound \u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mlen\u001B[39m(links)\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m linked pdfs.\u001B[39m\u001B[33m'\u001B[39m)\n\u001B[32m     65\u001B[39m     all_c = parallel(\u001B[38;5;28mself\u001B[39m.read_link, links, threadpool=\u001B[38;5;28;01mTrue\u001B[39;00m, dest=\u001B[38;5;28mself\u001B[39m.dest/\u001B[33m'\u001B[39m\u001B[33mlinks\u001B[39m\u001B[33m'\u001B[39m)\n",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[4]\u001B[39m\u001B[32m, line 54\u001B[39m, in \u001B[36mBruegelDataset.__call__.<locals>.get_linked_pdfs\u001B[39m\u001B[34m(doc, filter)\u001B[39m\n\u001B[32m     53\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34mget_linked_pdfs\u001B[39m(doc, \u001B[38;5;28mfilter\u001B[39m=\u001B[38;5;28;01mTrue\u001B[39;00m):\n\u001B[32m---> \u001B[39m\u001B[32m54\u001B[39m     links = \u001B[43mdoc\u001B[49m.map(\u001B[38;5;28;01mlambda\u001B[39;00m p: p.links.map(\u001B[38;5;28;01mlambda\u001B[39;00m l: l.uri)).concat().unique()\n\u001B[32m     55\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mfilter\u001B[39m: links = links.filter(\u001B[38;5;28mself\u001B[39m._is_pdf_link)\n\u001B[32m     56\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m links[:sample_size]\n",
      "\u001B[36mFile \u001B[39m\u001B[32m/Applications/PyCharm.app/Contents/plugins/python-ce/helpers/pydev/_pydevd_bundle/pydevd_frame.py:755\u001B[39m, in \u001B[36mPyDBFrame.trace_dispatch\u001B[39m\u001B[34m(self, frame, event, arg)\u001B[39m\n\u001B[32m    753\u001B[39m \u001B[38;5;66;03m# if thread has a suspend flag, we suspend with a busy wait\u001B[39;00m\n\u001B[32m    754\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m info.pydev_state == STATE_SUSPEND:\n\u001B[32m--> \u001B[39m\u001B[32m755\u001B[39m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mdo_wait_suspend\u001B[49m\u001B[43m(\u001B[49m\u001B[43mthread\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mframe\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mevent\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43marg\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    756\u001B[39m     \u001B[38;5;66;03m# No need to reset frame.f_trace to keep the same trace function.\u001B[39;00m\n\u001B[32m    757\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m.trace_dispatch\n",
      "\u001B[36mFile \u001B[39m\u001B[32m/Applications/PyCharm.app/Contents/plugins/python-ce/helpers/pydev/_pydevd_bundle/pydevd_frame.py:412\u001B[39m, in \u001B[36mPyDBFrame.do_wait_suspend\u001B[39m\u001B[34m(self, *args, **kwargs)\u001B[39m\n\u001B[32m    411\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34mdo_wait_suspend\u001B[39m(\u001B[38;5;28mself\u001B[39m, *args, **kwargs):\n\u001B[32m--> \u001B[39m\u001B[32m412\u001B[39m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_args\u001B[49m\u001B[43m[\u001B[49m\u001B[32;43m0\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m.\u001B[49m\u001B[43mdo_wait_suspend\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m/Applications/PyCharm.app/Contents/plugins/python-ce/helpers/pydev/pydevd.py:1220\u001B[39m, in \u001B[36mPyDB.do_wait_suspend\u001B[39m\u001B[34m(self, thread, frame, event, arg, send_suspend_message, is_unhandled_exception)\u001B[39m\n\u001B[32m   1217\u001B[39m         from_this_thread.append(frame_id)\n\u001B[32m   1219\u001B[39m \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mself\u001B[39m._threads_suspended_single_notification.notify_thread_suspended(thread_id, stop_reason):\n\u001B[32m-> \u001B[39m\u001B[32m1220\u001B[39m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_do_wait_suspend\u001B[49m\u001B[43m(\u001B[49m\u001B[43mthread\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mframe\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mevent\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43marg\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msuspend_type\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mfrom_this_thread\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m/Applications/PyCharm.app/Contents/plugins/python-ce/helpers/pydev/pydevd.py:1235\u001B[39m, in \u001B[36mPyDB._do_wait_suspend\u001B[39m\u001B[34m(self, thread, frame, event, arg, suspend_type, from_this_thread)\u001B[39m\n\u001B[32m   1232\u001B[39m             \u001B[38;5;28mself\u001B[39m._call_mpl_hook()\n\u001B[32m   1234\u001B[39m         \u001B[38;5;28mself\u001B[39m.process_internal_commands()\n\u001B[32m-> \u001B[39m\u001B[32m1235\u001B[39m         \u001B[43mtime\u001B[49m\u001B[43m.\u001B[49m\u001B[43msleep\u001B[49m\u001B[43m(\u001B[49m\u001B[32;43m0.01\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[32m   1237\u001B[39m \u001B[38;5;28mself\u001B[39m.cancel_async_evaluation(get_current_thread_id(thread), \u001B[38;5;28mstr\u001B[39m(\u001B[38;5;28mid\u001B[39m(frame)))\n\u001B[32m   1239\u001B[39m \u001B[38;5;66;03m# process any stepping instructions\u001B[39;00m\n",
      "\u001B[31mKeyboardInterrupt\u001B[39m: "
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "#### Patching is a great way to add functionalities to existing classes. It works on all python classes\n",
    "Here we are modifying the title in metadata with a better value. We get it as part of the breugel web scraping."
   ],
   "id": "3a0b1695a0351fdf"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-09T09:13:32.486998Z",
     "start_time": "2025-11-09T09:13:32.484071Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#| export\n",
    "@patch\n",
    "def read_pdfs(self:BruegelDataset, fn=noop):\n",
    "    def update_meta(p):\n",
    "        if not fn(p): return None\n",
    "        d = read_pdf(p.path)\n",
    "        d['name'] = d.metadata.title\n",
    "        d.metadata.title = p.title\n",
    "        return d\n",
    "    return maps(update_meta, self.pdfs)"
   ],
   "id": "8f65aa86ce717748",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Let's load the dataset. it takes a bit the first time around as it downloads about 10 pdfs. check your examples folder for `breugel_dataset`",
   "id": "d16c94b3bf6720d5"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-09T09:13:34.984517Z",
     "start_time": "2025-11-09T09:13:34.982272Z"
    }
   },
   "cell_type": "code",
   "source": "print('no. of pdfs: ', len(b.pdfs))",
   "id": "d7fbb25c835453a8",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no. of pdfs:  817\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Let's read the first pdf.",
   "id": "f00f128135c898ea"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-09T09:14:20.350268Z",
     "start_time": "2025-11-09T09:14:20.214714Z"
    }
   },
   "cell_type": "code",
   "source": "doc = first(b.read_pdfs())",
   "id": "6d2e7d36b3ca16b5",
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Now let's load the pdfs into the db. The db is already patched with a whole bunch of syntactic sugars. Checkout `litesearch.data` for more info",
   "id": "4397b806a3463cd2"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-09T09:14:53.609325Z",
     "start_time": "2025-11-09T09:14:49.943945Z"
    }
   },
   "cell_type": "code",
   "source": "db.pdf_ingest(first(b.read_pdfs()))",
   "id": "c671586761f097b5",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/71293/code/thedu/.venv/lib/python3.13/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "\u001B[32m2025-11-09 20:14:50.502\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.base\u001B[0m:\u001B[36m__init__\u001B[0m:\u001B[36m32\u001B[0m - \u001B[34m\u001B[1mInitialized RecursiveChunker\u001B[0m\n",
      "\u001B[32m2025-11-09 20:14:50.503\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.recursive\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m368\u001B[0m - \u001B[34m\u001B[1mStarting recursive chunking for text of length 17283\u001B[0m\n",
      "\u001B[32m2025-11-09 20:14:50.513\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.recursive\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m370\u001B[0m - \u001B[1mCreated 10 chunks using recursive chunking\u001B[0m\n",
      "\u001B[32m2025-11-09 20:14:52.152\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.base\u001B[0m:\u001B[36m__init__\u001B[0m:\u001B[36m32\u001B[0m - \u001B[34m\u001B[1mInitialized SemanticChunker\u001B[0m\n",
      "\u001B[32m2025-11-09 20:14:52.153\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 2001\u001B[0m\n",
      "\u001B[32m2025-11-09 20:14:52.154\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 40 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:14:52.157\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 12 semantic chunks from 40 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:14:52.158\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 1860\u001B[0m\n",
      "\u001B[32m2025-11-09 20:14:52.159\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 32 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:14:52.162\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 14 semantic chunks from 32 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:14:52.162\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 1852\u001B[0m\n",
      "\u001B[32m2025-11-09 20:14:52.163\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 30 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:14:52.166\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 13 semantic chunks from 30 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:14:52.167\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 1885\u001B[0m\n",
      "\u001B[32m2025-11-09 20:14:52.167\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 33 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:14:52.170\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 13 semantic chunks from 33 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:14:52.170\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 1879\u001B[0m\n",
      "\u001B[32m2025-11-09 20:14:52.171\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 33 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:14:52.174\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 12 semantic chunks from 33 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:14:52.175\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 1945\u001B[0m\n",
      "\u001B[32m2025-11-09 20:14:52.175\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 36 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:14:52.179\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 14 semantic chunks from 36 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:14:52.179\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 1880\u001B[0m\n",
      "\u001B[32m2025-11-09 20:14:52.180\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 30 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:14:52.183\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 13 semantic chunks from 30 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:14:52.183\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 1886\u001B[0m\n",
      "\u001B[32m2025-11-09 20:14:52.184\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 29 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:14:52.187\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 10 semantic chunks from 29 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:14:52.187\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 1851\u001B[0m\n",
      "\u001B[32m2025-11-09 20:14:52.188\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 31 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:14:52.190\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 10 semantic chunks from 31 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:14:52.191\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 244\u001B[0m\n",
      "\u001B[32m2025-11-09 20:14:52.191\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 5 sentences for semantic analysis\u001B[0m\n",
      "/Users/71293/code/thedu/.venv/lib/python3.13/site-packages/chonkie/embeddings/model2vec.py:64: RuntimeWarning: invalid value encountered in divide\n",
      "  return np.divide(\n",
      "\u001B[32m2025-11-09 20:14:52.193\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 1 semantic chunks from 5 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:14:52.194\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.refinery.overlap\u001B[0m:\u001B[36mrefine\u001B[0m:\u001B[36m456\u001B[0m - \u001B[34m\u001B[1mStarting overlap refinery for 112 chunks with method=suffix, mode=token\u001B[0m\n",
      "/Users/71293/code/thedu/.venv/lib/python3.13/site-packages/chonkie/refinery/overlap.py:350: UserWarning: Context size is greater than the chunk size. The entire chunk will be returned as the context.\n",
      "  warnings.warn(\n",
      "\u001B[32m2025-11-09 20:14:52.196\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.refinery.overlap\u001B[0m:\u001B[36mrefine\u001B[0m:\u001B[36m481\u001B[0m - \u001B[1mOverlap refinement complete: added context to 112 chunks\u001B[0m\n",
      "\u001B[32m2025-11-09 20:14:53.583\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.refinery.embedding\u001B[0m:\u001B[36mrefine\u001B[0m:\u001B[36m51\u001B[0m - \u001B[34m\u001B[1mStarting embedding refinery for 112 chunks\u001B[0m\n",
      "\u001B[32m2025-11-09 20:14:53.590\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.refinery.embedding\u001B[0m:\u001B[36mrefine\u001B[0m:\u001B[36m56\u001B[0m - \u001B[1mEmbedding refinement complete: added embeddings to 112 chunks\u001B[0m\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "The above will work, but will load a new chunking pipe everytime. An efficient way is to get the default pipe of create your own. We use chonkie for chunking and embedding. To reduce the number of documents we're also filtering out non english docs. Checkout their docs for more information: https://docs.chonkie.ai/oss",
   "id": "95fbdd854901f55b"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-09T09:17:23.842374Z",
     "start_time": "2025-11-09T09:16:28.600864Z"
    }
   },
   "cell_type": "code",
   "source": [
    "pipe = pdf_pipe()\n",
    "only_eng = lambda p: p.path.stem.endswith('_eng')\n",
    "[db.pdf_ingest(p, pipe) for p in b.read_pdfs(fn=only_eng) if p]"
   ],
   "id": "f4867eb74318b695",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32m2025-11-09 20:16:29.195\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.base\u001B[0m:\u001B[36m__init__\u001B[0m:\u001B[36m32\u001B[0m - \u001B[34m\u001B[1mInitialized RecursiveChunker\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:29.196\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.recursive\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m368\u001B[0m - \u001B[34m\u001B[1mStarting recursive chunking for text of length 16789\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:29.202\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.recursive\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m370\u001B[0m - \u001B[1mCreated 2 chunks using recursive chunking\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:30.881\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.base\u001B[0m:\u001B[36m__init__\u001B[0m:\u001B[36m32\u001B[0m - \u001B[34m\u001B[1mInitialized SemanticChunker\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:30.881\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 8252\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:30.882\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 128 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:30.888\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 47 semantic chunks from 128 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:30.889\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 8537\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:30.890\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 133 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:30.897\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 46 semantic chunks from 133 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:30.898\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.refinery.overlap\u001B[0m:\u001B[36mrefine\u001B[0m:\u001B[36m456\u001B[0m - \u001B[34m\u001B[1mStarting overlap refinery for 93 chunks with method=suffix, mode=token\u001B[0m\n",
      "/Users/71293/code/thedu/.venv/lib/python3.13/site-packages/chonkie/refinery/overlap.py:350: UserWarning: Context size is greater than the chunk size. The entire chunk will be returned as the context.\n",
      "  warnings.warn(\n",
      "\u001B[32m2025-11-09 20:16:30.899\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.refinery.overlap\u001B[0m:\u001B[36mrefine\u001B[0m:\u001B[36m481\u001B[0m - \u001B[1mOverlap refinement complete: added context to 93 chunks\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:32.062\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.refinery.embedding\u001B[0m:\u001B[36mrefine\u001B[0m:\u001B[36m51\u001B[0m - \u001B[34m\u001B[1mStarting embedding refinery for 93 chunks\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:32.067\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.refinery.embedding\u001B[0m:\u001B[36mrefine\u001B[0m:\u001B[36m56\u001B[0m - \u001B[1mEmbedding refinement complete: added embeddings to 93 chunks\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:32.158\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.recursive\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m368\u001B[0m - \u001B[34m\u001B[1mStarting recursive chunking for text of length 14450\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:32.163\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.recursive\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m370\u001B[0m - \u001B[1mCreated 2 chunks using recursive chunking\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:32.163\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 8071\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:32.164\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 135 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:32.171\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 47 semantic chunks from 135 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:32.171\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 6379\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:32.172\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 103 sentences for semantic analysis\u001B[0m\n",
      "/Users/71293/code/thedu/.venv/lib/python3.13/site-packages/chonkie/embeddings/model2vec.py:64: RuntimeWarning: invalid value encountered in divide\n",
      "  return np.divide(\n",
      "\u001B[32m2025-11-09 20:16:32.177\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 30 semantic chunks from 103 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:32.178\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.refinery.overlap\u001B[0m:\u001B[36mrefine\u001B[0m:\u001B[36m456\u001B[0m - \u001B[34m\u001B[1mStarting overlap refinery for 77 chunks with method=suffix, mode=token\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:32.179\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.refinery.overlap\u001B[0m:\u001B[36mrefine\u001B[0m:\u001B[36m481\u001B[0m - \u001B[1mOverlap refinement complete: added context to 77 chunks\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:32.179\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.refinery.embedding\u001B[0m:\u001B[36mrefine\u001B[0m:\u001B[36m51\u001B[0m - \u001B[34m\u001B[1mStarting embedding refinery for 77 chunks\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:32.183\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.refinery.embedding\u001B[0m:\u001B[36mrefine\u001B[0m:\u001B[36m56\u001B[0m - \u001B[1mEmbedding refinement complete: added embeddings to 77 chunks\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:32.285\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.recursive\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m368\u001B[0m - \u001B[34m\u001B[1mStarting recursive chunking for text of length 15693\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:32.289\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.recursive\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m370\u001B[0m - \u001B[1mCreated 2 chunks using recursive chunking\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:32.290\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 7930\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:32.291\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 131 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:32.298\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 45 semantic chunks from 131 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:32.298\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 7763\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:32.300\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 124 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:32.305\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 41 semantic chunks from 124 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:32.306\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.refinery.overlap\u001B[0m:\u001B[36mrefine\u001B[0m:\u001B[36m456\u001B[0m - \u001B[34m\u001B[1mStarting overlap refinery for 86 chunks with method=suffix, mode=token\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:32.307\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.refinery.overlap\u001B[0m:\u001B[36mrefine\u001B[0m:\u001B[36m481\u001B[0m - \u001B[1mOverlap refinement complete: added context to 86 chunks\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:32.307\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.refinery.embedding\u001B[0m:\u001B[36mrefine\u001B[0m:\u001B[36m51\u001B[0m - \u001B[34m\u001B[1mStarting embedding refinery for 86 chunks\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:32.311\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.refinery.embedding\u001B[0m:\u001B[36mrefine\u001B[0m:\u001B[36m56\u001B[0m - \u001B[1mEmbedding refinement complete: added embeddings to 86 chunks\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:32.382\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.recursive\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m368\u001B[0m - \u001B[34m\u001B[1mStarting recursive chunking for text of length 9948\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:32.385\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.recursive\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m370\u001B[0m - \u001B[1mCreated 2 chunks using recursive chunking\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:32.385\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 7946\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:32.386\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 128 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:32.392\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 39 semantic chunks from 128 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:32.393\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 2002\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:32.393\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 33 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:32.395\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 10 semantic chunks from 33 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:32.396\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.refinery.overlap\u001B[0m:\u001B[36mrefine\u001B[0m:\u001B[36m456\u001B[0m - \u001B[34m\u001B[1mStarting overlap refinery for 49 chunks with method=suffix, mode=token\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:32.397\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.refinery.overlap\u001B[0m:\u001B[36mrefine\u001B[0m:\u001B[36m481\u001B[0m - \u001B[1mOverlap refinement complete: added context to 49 chunks\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:32.397\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.refinery.embedding\u001B[0m:\u001B[36mrefine\u001B[0m:\u001B[36m51\u001B[0m - \u001B[34m\u001B[1mStarting embedding refinery for 49 chunks\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:32.400\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.refinery.embedding\u001B[0m:\u001B[36mrefine\u001B[0m:\u001B[36m56\u001B[0m - \u001B[1mEmbedding refinement complete: added embeddings to 49 chunks\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:32.582\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.recursive\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m368\u001B[0m - \u001B[34m\u001B[1mStarting recursive chunking for text of length 24538\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:32.588\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.recursive\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m370\u001B[0m - \u001B[1mCreated 3 chunks using recursive chunking\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:32.588\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 7834\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:32.590\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 128 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:32.596\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 46 semantic chunks from 128 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:32.596\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 8596\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:32.598\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 130 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:32.604\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 46 semantic chunks from 130 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:32.604\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 8108\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:32.605\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 136 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:32.612\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 46 semantic chunks from 136 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:32.612\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.refinery.overlap\u001B[0m:\u001B[36mrefine\u001B[0m:\u001B[36m456\u001B[0m - \u001B[34m\u001B[1mStarting overlap refinery for 138 chunks with method=suffix, mode=token\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:32.614\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.refinery.overlap\u001B[0m:\u001B[36mrefine\u001B[0m:\u001B[36m481\u001B[0m - \u001B[1mOverlap refinement complete: added context to 138 chunks\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:32.614\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.refinery.embedding\u001B[0m:\u001B[36mrefine\u001B[0m:\u001B[36m51\u001B[0m - \u001B[34m\u001B[1mStarting embedding refinery for 138 chunks\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:32.621\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.refinery.embedding\u001B[0m:\u001B[36mrefine\u001B[0m:\u001B[36m56\u001B[0m - \u001B[1mEmbedding refinement complete: added embeddings to 138 chunks\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:35.835\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.recursive\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m368\u001B[0m - \u001B[34m\u001B[1mStarting recursive chunking for text of length 434110\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:35.945\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.recursive\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m370\u001B[0m - \u001B[1mCreated 59 chunks using recursive chunking\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:35.946\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 5490\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:35.947\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 124 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:35.953\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 42 semantic chunks from 124 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:35.953\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 6905\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:35.954\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 161 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:35.960\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 59 semantic chunks from 161 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:35.961\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 6927\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:35.962\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 130 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:35.968\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 40 semantic chunks from 130 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:35.968\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 7925\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:35.969\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 128 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:35.976\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 47 semantic chunks from 128 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:35.977\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 7921\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:35.978\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 126 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:35.983\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 48 semantic chunks from 126 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:35.983\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 8426\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:35.985\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 129 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:35.991\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 46 semantic chunks from 129 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:35.992\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 8124\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:35.993\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 127 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:35.999\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 41 semantic chunks from 127 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:35.999\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 8001\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:36.000\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 124 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:36.006\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 38 semantic chunks from 124 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:36.006\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 7344\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:36.007\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 116 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:36.013\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 36 semantic chunks from 116 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:36.013\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 7416\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:36.014\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 123 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:36.021\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 39 semantic chunks from 123 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:36.022\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 8112\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:36.023\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 125 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:36.028\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 48 semantic chunks from 125 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:36.029\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 8144\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:36.030\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 126 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:36.036\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 42 semantic chunks from 126 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:36.036\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 7950\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:36.037\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 125 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:36.043\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 41 semantic chunks from 125 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:36.043\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 7934\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:36.044\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 122 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:36.050\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 41 semantic chunks from 122 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:36.051\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 8220\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:36.052\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 130 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:36.058\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 46 semantic chunks from 130 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:36.058\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 7848\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:36.059\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 124 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:36.066\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 43 semantic chunks from 124 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:36.066\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 7693\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:36.067\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 119 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:36.073\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 46 semantic chunks from 119 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:36.073\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 8257\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:36.074\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 129 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:36.080\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 50 semantic chunks from 129 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:36.081\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 8376\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:36.082\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 129 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:36.089\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 46 semantic chunks from 129 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:36.089\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 8013\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:36.090\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 126 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:36.097\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 41 semantic chunks from 126 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:36.097\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 7720\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:36.099\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 120 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:36.104\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 43 semantic chunks from 120 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:36.105\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 8242\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:36.106\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 128 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:36.111\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 44 semantic chunks from 128 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:36.112\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 8023\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:36.113\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 127 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:36.118\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 42 semantic chunks from 127 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:36.119\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 8258\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:36.120\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 130 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:36.126\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 47 semantic chunks from 130 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:36.127\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 8022\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:36.128\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 122 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:36.134\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 38 semantic chunks from 122 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:36.134\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 7786\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:36.135\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 125 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:36.141\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 46 semantic chunks from 125 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:36.141\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 7723\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:36.142\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 121 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:36.148\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 39 semantic chunks from 121 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:36.148\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 7794\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:36.150\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 123 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:36.155\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 46 semantic chunks from 123 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:36.156\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 7856\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:36.157\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 122 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:36.163\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 42 semantic chunks from 122 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:36.163\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 8187\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:36.164\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 127 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:36.170\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 48 semantic chunks from 127 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:36.171\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 8271\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:36.172\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 128 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:36.178\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 41 semantic chunks from 128 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:36.178\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 7662\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:36.180\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 133 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:36.186\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 50 semantic chunks from 133 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:36.186\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 8400\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:36.188\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 131 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:36.193\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 48 semantic chunks from 131 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:36.194\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 7844\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:36.195\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 121 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:36.201\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 40 semantic chunks from 121 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:36.201\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 8000\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:36.202\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 122 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:36.209\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 43 semantic chunks from 122 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:36.209\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 7659\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:36.210\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 120 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:36.216\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 38 semantic chunks from 120 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:36.216\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 7660\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:36.217\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 121 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:36.223\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 38 semantic chunks from 121 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:36.224\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 7768\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:36.225\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 128 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:36.231\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 46 semantic chunks from 128 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:36.232\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 8365\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:36.233\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 130 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:36.239\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 47 semantic chunks from 130 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:36.239\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 8094\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:36.240\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 135 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:36.246\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 43 semantic chunks from 135 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:36.247\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 8530\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:36.248\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 128 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:36.254\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 46 semantic chunks from 128 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:36.255\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 7551\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:36.256\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 116 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:36.261\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 39 semantic chunks from 116 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:36.262\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 7712\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:36.263\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 122 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:36.270\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 40 semantic chunks from 122 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:36.270\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 8475\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:36.271\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 135 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:36.277\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 50 semantic chunks from 135 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:36.278\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 7892\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:36.279\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 128 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:36.284\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 46 semantic chunks from 128 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:36.285\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 6606\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:36.286\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 112 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:36.292\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 36 semantic chunks from 112 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:36.292\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 7316\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:36.293\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 115 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:36.299\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 41 semantic chunks from 115 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:36.299\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 5411\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:36.300\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 111 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:36.306\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 38 semantic chunks from 111 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:36.306\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 5374\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:36.307\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 147 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:36.314\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 45 semantic chunks from 147 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:36.314\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 5531\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:36.315\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 148 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:36.321\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 38 semantic chunks from 148 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:36.322\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 5633\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:36.323\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 145 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:36.329\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 35 semantic chunks from 145 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:36.330\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 5616\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:36.331\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 147 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:36.337\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 43 semantic chunks from 147 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:36.337\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 5633\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:36.338\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 143 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:36.344\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 46 semantic chunks from 143 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:36.345\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 5447\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:36.346\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 143 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:36.352\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 42 semantic chunks from 143 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:36.352\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 5336\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:36.353\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 148 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:36.359\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 34 semantic chunks from 148 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:36.359\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 6227\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:36.360\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 160 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:36.366\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 42 semantic chunks from 160 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:36.367\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 5806\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:36.368\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 155 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:36.374\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 42 semantic chunks from 155 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:36.375\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 4859\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:36.376\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 129 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:36.382\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 34 semantic chunks from 129 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:36.382\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 4795\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:36.383\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 147 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:36.389\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 53 semantic chunks from 147 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:36.389\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.refinery.overlap\u001B[0m:\u001B[36mrefine\u001B[0m:\u001B[36m456\u001B[0m - \u001B[34m\u001B[1mStarting overlap refinery for 2539 chunks with method=suffix, mode=token\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:36.418\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.refinery.overlap\u001B[0m:\u001B[36mrefine\u001B[0m:\u001B[36m481\u001B[0m - \u001B[1mOverlap refinement complete: added context to 2539 chunks\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:36.419\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.refinery.embedding\u001B[0m:\u001B[36mrefine\u001B[0m:\u001B[36m51\u001B[0m - \u001B[34m\u001B[1mStarting embedding refinery for 2539 chunks\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:36.519\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.refinery.embedding\u001B[0m:\u001B[36mrefine\u001B[0m:\u001B[36m56\u001B[0m - \u001B[1mEmbedding refinement complete: added embeddings to 2539 chunks\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:40.046\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.recursive\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m368\u001B[0m - \u001B[34m\u001B[1mStarting recursive chunking for text of length 442293\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:40.158\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.recursive\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m370\u001B[0m - \u001B[1mCreated 60 chunks using recursive chunking\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:40.158\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 5453\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:40.159\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 123 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:40.166\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 44 semantic chunks from 123 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:40.168\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 6963\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:40.170\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 160 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:40.176\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 57 semantic chunks from 160 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:40.177\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 6922\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:40.178\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 131 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:40.183\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 42 semantic chunks from 131 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:40.184\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 7870\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:40.185\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 126 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:40.191\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 47 semantic chunks from 126 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:40.191\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 8037\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:40.192\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 128 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:40.198\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 47 semantic chunks from 128 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:40.199\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 8419\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:40.200\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 129 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:40.206\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 46 semantic chunks from 129 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:40.207\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 8153\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:40.208\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 126 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:40.214\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 44 semantic chunks from 126 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:40.214\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 8044\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:40.216\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 125 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:40.221\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 40 semantic chunks from 125 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:40.222\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 7344\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:40.223\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 116 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:40.228\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 36 semantic chunks from 116 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:40.229\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 7416\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:40.230\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 123 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:40.236\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 39 semantic chunks from 123 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:40.237\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 8112\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:40.238\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 125 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:40.244\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 47 semantic chunks from 125 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:40.245\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 8144\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:40.246\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 126 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:40.252\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 42 semantic chunks from 126 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:40.252\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 7950\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:40.253\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 125 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:40.259\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 41 semantic chunks from 125 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:40.260\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 7934\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:40.261\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 122 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:40.266\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 41 semantic chunks from 122 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:40.267\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 8220\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:40.268\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 130 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:40.274\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 46 semantic chunks from 130 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:40.274\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 7848\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:40.275\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 124 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:40.281\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 45 semantic chunks from 124 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:40.281\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 7693\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:40.282\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 119 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:40.288\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 46 semantic chunks from 119 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:40.289\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 8257\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:40.290\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 129 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:40.295\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 50 semantic chunks from 129 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:40.296\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 8376\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:40.297\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 129 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:40.304\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 46 semantic chunks from 129 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:40.304\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 8013\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:40.305\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 126 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:40.311\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 40 semantic chunks from 126 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:40.311\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 7720\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:40.312\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 120 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:40.318\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 44 semantic chunks from 120 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:40.319\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 8242\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:40.320\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 128 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:40.325\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 45 semantic chunks from 128 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:40.326\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 8023\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:40.327\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 127 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:40.333\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 41 semantic chunks from 127 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:40.333\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 8258\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:40.334\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 130 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:40.341\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 48 semantic chunks from 130 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:40.341\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 8022\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:40.342\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 122 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:40.348\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 38 semantic chunks from 122 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:40.348\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 7786\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:40.349\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 125 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:40.355\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 46 semantic chunks from 125 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:40.356\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 7723\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:40.357\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 121 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:40.362\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 38 semantic chunks from 121 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:40.363\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 7794\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:40.364\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 123 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:40.370\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 46 semantic chunks from 123 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:40.370\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 7503\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:40.372\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 121 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:40.377\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 38 semantic chunks from 121 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:40.378\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 7789\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:40.379\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 124 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:40.385\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 40 semantic chunks from 124 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:40.385\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 8204\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:40.386\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 127 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:40.392\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 48 semantic chunks from 127 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:40.392\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 8229\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:40.393\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 127 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:40.399\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 40 semantic chunks from 127 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:40.400\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 7786\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:40.401\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 136 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:40.408\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 48 semantic chunks from 136 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:40.408\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 8331\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:40.409\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 129 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:40.415\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 48 semantic chunks from 129 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:40.416\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 7796\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:40.417\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 121 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:40.423\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 40 semantic chunks from 121 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:40.424\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 8108\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:40.425\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 123 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:40.430\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 42 semantic chunks from 123 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:40.431\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 7785\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:40.432\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 123 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:40.437\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 38 semantic chunks from 123 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:40.438\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 7562\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:40.439\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 119 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:40.444\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 38 semantic chunks from 119 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:40.445\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 7675\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:40.446\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 125 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:40.452\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 47 semantic chunks from 125 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:40.452\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 8523\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:40.454\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 135 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:40.459\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 46 semantic chunks from 135 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:40.460\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 8020\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:40.461\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 134 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:40.467\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 44 semantic chunks from 134 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:40.468\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 8558\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:40.469\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 128 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:40.475\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 45 semantic chunks from 128 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:40.476\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 7579\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:40.477\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 117 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:40.483\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 41 semantic chunks from 117 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:40.483\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 7831\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:40.484\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 122 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:40.490\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 39 semantic chunks from 122 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:40.491\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 8366\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:40.492\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 136 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:40.498\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 46 semantic chunks from 136 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:40.499\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 7978\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:40.500\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 128 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:40.506\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 46 semantic chunks from 128 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:40.507\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 6545\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:40.508\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 112 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:40.514\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 38 semantic chunks from 112 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:40.514\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 7325\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:40.515\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 115 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:40.521\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 38 semantic chunks from 115 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:40.521\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 5564\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:40.522\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 111 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:40.528\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 38 semantic chunks from 111 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:40.529\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 5378\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:40.530\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 145 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:40.535\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 42 semantic chunks from 145 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:40.536\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 5494\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:40.537\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 149 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:40.543\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 39 semantic chunks from 149 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:40.543\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 5592\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:40.544\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 144 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:40.551\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 34 semantic chunks from 144 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:40.551\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 5657\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:40.552\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 148 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:40.558\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 46 semantic chunks from 148 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:40.559\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 5626\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:40.560\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 143 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:40.565\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 48 semantic chunks from 143 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:40.566\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 5461\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:40.567\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 142 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:40.573\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 42 semantic chunks from 142 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:40.573\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 5381\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:40.574\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 150 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:40.579\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 34 semantic chunks from 150 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:40.580\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 6119\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:40.581\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 158 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:40.587\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 42 semantic chunks from 158 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:40.588\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 5867\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:40.589\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 155 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:40.595\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 42 semantic chunks from 155 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:40.596\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 4886\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:40.597\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 130 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:40.602\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 34 semantic chunks from 130 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:40.603\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 5039\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:40.604\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 154 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:40.610\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 54 semantic chunks from 154 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:40.611\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.refinery.overlap\u001B[0m:\u001B[36mrefine\u001B[0m:\u001B[36m456\u001B[0m - \u001B[34m\u001B[1mStarting overlap refinery for 2577 chunks with method=suffix, mode=token\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:40.622\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.refinery.overlap\u001B[0m:\u001B[36mrefine\u001B[0m:\u001B[36m481\u001B[0m - \u001B[1mOverlap refinement complete: added context to 2577 chunks\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:40.622\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.refinery.embedding\u001B[0m:\u001B[36mrefine\u001B[0m:\u001B[36m51\u001B[0m - \u001B[34m\u001B[1mStarting embedding refinery for 2577 chunks\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:40.724\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.refinery.embedding\u001B[0m:\u001B[36mrefine\u001B[0m:\u001B[36m56\u001B[0m - \u001B[1mEmbedding refinement complete: added embeddings to 2577 chunks\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:41.589\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.recursive\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m368\u001B[0m - \u001B[34m\u001B[1mStarting recursive chunking for text of length 108318\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:41.618\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.recursive\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m370\u001B[0m - \u001B[1mCreated 15 chunks using recursive chunking\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:41.619\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 6811\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:41.620\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 129 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:41.626\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 49 semantic chunks from 129 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:41.627\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 8329\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:41.628\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 133 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:41.634\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 39 semantic chunks from 133 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:41.635\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 8455\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:41.636\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 132 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:41.642\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 46 semantic chunks from 132 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:41.642\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 8319\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:41.644\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 142 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:41.650\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 51 semantic chunks from 142 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:41.650\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 9165\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:41.651\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 144 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:41.658\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 49 semantic chunks from 144 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:41.658\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 9029\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:41.659\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 140 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:41.666\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 47 semantic chunks from 140 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:41.666\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 8708\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:41.667\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 139 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:41.673\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 48 semantic chunks from 139 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:41.674\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 8131\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:41.675\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 134 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:41.681\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 49 semantic chunks from 134 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:41.681\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 8177\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:41.682\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 130 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:41.688\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 48 semantic chunks from 130 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:41.689\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 7115\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:41.690\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 116 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:41.696\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 37 semantic chunks from 116 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:41.697\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 3739\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:41.697\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 90 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:41.702\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 31 semantic chunks from 90 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:41.703\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 4360\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:41.703\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 108 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:41.709\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 37 semantic chunks from 108 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:41.709\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 7448\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:41.710\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 120 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:41.716\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 42 semantic chunks from 120 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:41.716\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 6608\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:41.717\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 128 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:41.723\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 38 semantic chunks from 128 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:41.723\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 3924\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:41.724\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 61 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:41.727\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 21 semantic chunks from 61 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:41.728\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.refinery.overlap\u001B[0m:\u001B[36mrefine\u001B[0m:\u001B[36m456\u001B[0m - \u001B[34m\u001B[1mStarting overlap refinery for 632 chunks with method=suffix, mode=token\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:41.735\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.refinery.overlap\u001B[0m:\u001B[36mrefine\u001B[0m:\u001B[36m481\u001B[0m - \u001B[1mOverlap refinement complete: added context to 632 chunks\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:41.736\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.refinery.embedding\u001B[0m:\u001B[36mrefine\u001B[0m:\u001B[36m51\u001B[0m - \u001B[34m\u001B[1mStarting embedding refinery for 632 chunks\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:41.760\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.refinery.embedding\u001B[0m:\u001B[36mrefine\u001B[0m:\u001B[36m56\u001B[0m - \u001B[1mEmbedding refinement complete: added embeddings to 632 chunks\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:43.474\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.recursive\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m368\u001B[0m - \u001B[34m\u001B[1mStarting recursive chunking for text of length 259567\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:43.537\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.recursive\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m370\u001B[0m - \u001B[1mCreated 31 chunks using recursive chunking\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:43.537\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 7466\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:43.538\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 128 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:43.545\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 42 semantic chunks from 128 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:43.545\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 8635\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:43.546\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 140 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:43.552\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 50 semantic chunks from 140 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:43.553\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 8703\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:43.554\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 144 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:43.560\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 46 semantic chunks from 144 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:43.560\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 8522\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:43.561\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 133 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:43.568\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 46 semantic chunks from 133 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:43.569\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 8826\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:43.570\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 137 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:43.576\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 46 semantic chunks from 137 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:43.576\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 8640\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:43.578\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 134 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:43.584\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 53 semantic chunks from 134 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:43.584\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 8713\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:43.585\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 138 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:43.591\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 46 semantic chunks from 138 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:43.592\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 8753\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:43.593\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 140 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:43.599\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 51 semantic chunks from 140 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:43.599\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 8981\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:43.600\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 144 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:43.606\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 44 semantic chunks from 144 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:43.607\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 8891\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:43.608\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 137 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:43.614\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 46 semantic chunks from 137 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:43.614\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 8585\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:43.615\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 139 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:43.621\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 54 semantic chunks from 139 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:43.622\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 8413\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:43.623\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 137 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:43.629\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 52 semantic chunks from 137 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:43.630\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 8349\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:43.631\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 130 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:43.636\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 41 semantic chunks from 130 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:43.637\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 8736\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:43.638\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 136 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:43.644\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 48 semantic chunks from 136 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:43.645\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 8870\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:43.646\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 132 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:43.652\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 45 semantic chunks from 132 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:43.653\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 8749\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:43.654\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 133 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:43.660\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 42 semantic chunks from 133 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:43.660\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 8884\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:43.661\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 135 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:43.668\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 37 semantic chunks from 135 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:43.668\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 8575\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:43.669\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 133 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:43.675\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 50 semantic chunks from 133 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:43.675\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 8724\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:43.676\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 134 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:43.683\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 47 semantic chunks from 134 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:43.683\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 8473\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:43.685\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 138 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:43.691\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 48 semantic chunks from 138 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:43.692\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 8330\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:43.692\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 131 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:43.698\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 45 semantic chunks from 131 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:43.699\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 8448\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:43.700\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 127 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:43.705\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 42 semantic chunks from 127 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:43.706\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 8677\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:43.707\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 126 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:43.712\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 42 semantic chunks from 126 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:43.713\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 8421\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:43.714\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 126 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:43.720\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 46 semantic chunks from 126 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:43.720\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 8169\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:43.721\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 136 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:43.727\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 40 semantic chunks from 136 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:43.727\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 8860\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:43.728\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 135 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:43.734\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 45 semantic chunks from 135 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:43.735\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 8605\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:43.736\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 131 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:43.742\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 43 semantic chunks from 131 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:43.743\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 7981\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:43.744\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 129 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:43.749\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 40 semantic chunks from 129 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:43.750\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 8875\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:43.751\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 133 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:43.757\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 46 semantic chunks from 133 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:43.758\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 9017\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:43.759\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 134 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:43.765\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 44 semantic chunks from 134 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:43.765\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 1696\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:43.766\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 27 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:43.768\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 10 semantic chunks from 27 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:43.768\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.refinery.overlap\u001B[0m:\u001B[36mrefine\u001B[0m:\u001B[36m456\u001B[0m - \u001B[34m\u001B[1mStarting overlap refinery for 1377 chunks with method=suffix, mode=token\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:43.785\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.refinery.overlap\u001B[0m:\u001B[36mrefine\u001B[0m:\u001B[36m481\u001B[0m - \u001B[1mOverlap refinement complete: added context to 1377 chunks\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:43.786\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.refinery.embedding\u001B[0m:\u001B[36mrefine\u001B[0m:\u001B[36m51\u001B[0m - \u001B[34m\u001B[1mStarting embedding refinery for 1377 chunks\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:43.837\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.refinery.embedding\u001B[0m:\u001B[36mrefine\u001B[0m:\u001B[36m56\u001B[0m - \u001B[1mEmbedding refinement complete: added embeddings to 1377 chunks\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:45.582\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.recursive\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m368\u001B[0m - \u001B[34m\u001B[1mStarting recursive chunking for text of length 263556\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:45.589\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.recursive\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m370\u001B[0m - \u001B[1mCreated 31 chunks using recursive chunking\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:45.589\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 7466\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:45.590\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 128 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:45.596\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 42 semantic chunks from 128 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:45.597\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 8635\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:45.598\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 140 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:45.604\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 50 semantic chunks from 140 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:45.605\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 8703\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:45.607\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 144 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:45.613\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 46 semantic chunks from 144 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:45.613\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 8522\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:45.615\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 133 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:45.620\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 46 semantic chunks from 133 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:45.621\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 8826\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:45.622\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 137 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:45.628\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 46 semantic chunks from 137 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:45.629\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 8640\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:45.630\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 134 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:45.636\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 54 semantic chunks from 134 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:45.636\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 8713\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:45.638\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 138 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:45.644\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 46 semantic chunks from 138 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:45.644\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 8753\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:45.645\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 140 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:45.652\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 51 semantic chunks from 140 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:45.653\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 8891\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:45.654\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 145 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:45.662\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 48 semantic chunks from 145 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:45.663\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 8917\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:45.664\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 138 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:45.670\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 44 semantic chunks from 138 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:45.670\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 8845\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:45.671\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 141 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:45.677\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 50 semantic chunks from 141 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:45.678\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 8362\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:45.679\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 132 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:45.685\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 48 semantic chunks from 132 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:45.686\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 8351\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:45.687\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 142 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:45.693\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 50 semantic chunks from 142 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:45.694\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 8662\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:45.695\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 125 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:45.701\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 40 semantic chunks from 125 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:45.701\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 8763\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:45.702\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 136 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:45.708\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 46 semantic chunks from 136 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:45.709\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 8740\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:45.710\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 132 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:45.716\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 47 semantic chunks from 132 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:45.717\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 9133\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:45.718\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 141 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:45.724\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 35 semantic chunks from 141 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:45.724\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 8373\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:45.725\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 128 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:45.732\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 45 semantic chunks from 128 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:45.732\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 8777\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:45.734\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 136 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:45.740\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 49 semantic chunks from 136 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:45.740\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 8460\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:45.742\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 134 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:45.748\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 47 semantic chunks from 134 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:45.748\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 8447\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:45.749\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 138 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:45.756\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 53 semantic chunks from 138 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:45.756\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 8327\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:45.757\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 126 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:45.763\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 42 semantic chunks from 126 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:45.764\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 8682\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:45.765\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 128 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:45.773\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 43 semantic chunks from 128 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:45.775\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 8449\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:45.776\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 123 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:45.781\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 41 semantic chunks from 123 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:45.782\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 8031\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:45.783\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 135 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:45.789\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 41 semantic chunks from 135 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:45.790\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 8910\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:45.791\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 137 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:45.797\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 42 semantic chunks from 137 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:45.798\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 8691\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:45.799\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 132 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:45.805\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 40 semantic chunks from 132 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:45.805\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 8101\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:45.807\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 129 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:45.812\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 44 semantic chunks from 129 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:45.813\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 8396\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:45.814\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 130 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:45.820\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 41 semantic chunks from 130 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:45.820\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 8991\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:45.821\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 132 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:45.827\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 50 semantic chunks from 132 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:45.828\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 5999\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:45.829\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 91 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:45.833\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 29 semantic chunks from 91 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:45.834\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.refinery.overlap\u001B[0m:\u001B[36mrefine\u001B[0m:\u001B[36m456\u001B[0m - \u001B[34m\u001B[1mStarting overlap refinery for 1396 chunks with method=suffix, mode=token\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:45.840\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.refinery.overlap\u001B[0m:\u001B[36mrefine\u001B[0m:\u001B[36m481\u001B[0m - \u001B[1mOverlap refinement complete: added context to 1396 chunks\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:45.841\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.refinery.embedding\u001B[0m:\u001B[36mrefine\u001B[0m:\u001B[36m51\u001B[0m - \u001B[34m\u001B[1mStarting embedding refinery for 1396 chunks\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:45.885\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.refinery.embedding\u001B[0m:\u001B[36mrefine\u001B[0m:\u001B[36m56\u001B[0m - \u001B[1mEmbedding refinement complete: added embeddings to 1396 chunks\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:46.764\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.recursive\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m368\u001B[0m - \u001B[34m\u001B[1mStarting recursive chunking for text of length 118052\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:46.792\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.recursive\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m370\u001B[0m - \u001B[1mCreated 14 chunks using recursive chunking\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:46.792\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 7539\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:46.793\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 129 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:46.800\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 41 semantic chunks from 129 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:46.801\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 9177\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:46.802\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 145 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:46.809\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 49 semantic chunks from 145 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:46.809\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 8984\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:46.810\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 140 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:46.816\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 43 semantic chunks from 140 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:46.816\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 8895\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:46.817\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 141 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:46.824\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 49 semantic chunks from 141 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:46.824\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 8851\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:46.825\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 139 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:46.831\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 51 semantic chunks from 139 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:46.832\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 8904\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:46.833\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 139 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:46.839\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 43 semantic chunks from 139 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:46.840\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 9181\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:46.841\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 147 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:46.846\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 50 semantic chunks from 147 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:46.847\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 8970\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:46.848\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 141 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:46.854\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 48 semantic chunks from 141 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:46.854\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 8243\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:46.855\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 137 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:46.861\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 46 semantic chunks from 137 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:46.861\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 8476\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:46.862\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 139 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:46.868\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 47 semantic chunks from 139 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:46.868\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 7917\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:46.869\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 132 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:46.875\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 43 semantic chunks from 132 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:46.876\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 8893\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:46.877\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 150 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:46.883\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 52 semantic chunks from 150 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:46.884\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 8748\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:46.885\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 144 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:46.890\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 45 semantic chunks from 144 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:46.891\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 5274\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:46.892\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 107 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:46.896\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 40 semantic chunks from 107 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:46.897\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.refinery.overlap\u001B[0m:\u001B[36mrefine\u001B[0m:\u001B[36m456\u001B[0m - \u001B[34m\u001B[1mStarting overlap refinery for 647 chunks with method=suffix, mode=token\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:46.904\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.refinery.overlap\u001B[0m:\u001B[36mrefine\u001B[0m:\u001B[36m481\u001B[0m - \u001B[1mOverlap refinement complete: added context to 647 chunks\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:46.905\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.refinery.embedding\u001B[0m:\u001B[36mrefine\u001B[0m:\u001B[36m51\u001B[0m - \u001B[34m\u001B[1mStarting embedding refinery for 647 chunks\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:46.929\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.refinery.embedding\u001B[0m:\u001B[36mrefine\u001B[0m:\u001B[36m56\u001B[0m - \u001B[1mEmbedding refinement complete: added embeddings to 647 chunks\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:48.432\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.recursive\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m368\u001B[0m - \u001B[34m\u001B[1mStarting recursive chunking for text of length 226254\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:48.488\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.recursive\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m370\u001B[0m - \u001B[1mCreated 28 chunks using recursive chunking\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:48.489\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 7647\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:48.490\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 125 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:48.497\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 37 semantic chunks from 125 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:48.497\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 8355\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:48.498\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 132 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:48.503\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 41 semantic chunks from 132 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:48.504\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 7918\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:48.505\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 130 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:48.511\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 41 semantic chunks from 130 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:48.512\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 8378\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:48.513\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 132 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:48.520\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 47 semantic chunks from 132 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:48.521\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 8101\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:48.522\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 127 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:48.528\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 45 semantic chunks from 127 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:48.528\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 8826\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:48.529\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 139 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:48.535\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 46 semantic chunks from 139 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:48.536\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 8547\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:48.537\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 140 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:48.543\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 50 semantic chunks from 140 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:48.543\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 9001\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:48.544\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 144 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:48.551\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 46 semantic chunks from 144 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:48.552\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 9097\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:48.553\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 140 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:48.559\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 51 semantic chunks from 140 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:48.560\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 8889\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:48.561\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 140 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:48.566\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 47 semantic chunks from 140 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:48.567\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 8427\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:48.568\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 136 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:48.573\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 50 semantic chunks from 136 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:48.574\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 8796\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:48.575\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 142 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:48.581\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 42 semantic chunks from 142 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:48.581\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 8795\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:48.582\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 141 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:48.588\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 42 semantic chunks from 141 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:48.588\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 8539\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:48.589\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 139 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:48.595\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 51 semantic chunks from 139 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:48.596\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 8228\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:48.597\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 134 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:48.603\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 41 semantic chunks from 134 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:48.604\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 8453\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:48.605\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 138 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:48.611\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 40 semantic chunks from 138 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:48.611\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 9009\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:48.612\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 140 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:48.618\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 42 semantic chunks from 140 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:48.618\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 8679\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:48.619\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 133 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:48.625\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 39 semantic chunks from 133 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:48.626\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 8257\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:48.627\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 132 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:48.634\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 38 semantic chunks from 132 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:48.635\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 8186\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:48.636\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 129 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:48.642\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 31 semantic chunks from 129 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:48.643\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 8938\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:48.644\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 143 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:48.651\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 45 semantic chunks from 143 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:48.651\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 8644\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:48.652\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 141 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:48.659\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 49 semantic chunks from 141 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:48.659\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 8631\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:48.661\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 137 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:48.666\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 46 semantic chunks from 137 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:48.667\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 8179\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:48.668\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 130 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:48.674\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 42 semantic chunks from 130 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:48.674\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 7219\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:48.675\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 126 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:48.681\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 41 semantic chunks from 126 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:48.682\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 6178\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:48.683\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 135 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:48.690\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 42 semantic chunks from 135 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:48.690\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 4360\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:48.691\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 136 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:48.697\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 39 semantic chunks from 136 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:48.697\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 3977\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:48.698\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 124 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:48.703\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 43 semantic chunks from 124 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:48.704\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.refinery.overlap\u001B[0m:\u001B[36mrefine\u001B[0m:\u001B[36m456\u001B[0m - \u001B[34m\u001B[1mStarting overlap refinery for 1214 chunks with method=suffix, mode=token\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:48.718\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.refinery.overlap\u001B[0m:\u001B[36mrefine\u001B[0m:\u001B[36m481\u001B[0m - \u001B[1mOverlap refinement complete: added context to 1214 chunks\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:48.719\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.refinery.embedding\u001B[0m:\u001B[36mrefine\u001B[0m:\u001B[36m51\u001B[0m - \u001B[34m\u001B[1mStarting embedding refinery for 1214 chunks\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:48.768\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.refinery.embedding\u001B[0m:\u001B[36mrefine\u001B[0m:\u001B[36m56\u001B[0m - \u001B[1mEmbedding refinement complete: added embeddings to 1214 chunks\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:51.396\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.recursive\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m368\u001B[0m - \u001B[34m\u001B[1mStarting recursive chunking for text of length 373618\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:51.484\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.recursive\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m370\u001B[0m - \u001B[1mCreated 46 chunks using recursive chunking\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:51.484\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 7408\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:51.486\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 140 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:51.492\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 47 semantic chunks from 140 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:51.493\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 8271\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:51.494\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 132 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:51.500\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 45 semantic chunks from 132 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:51.501\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 8259\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:51.502\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 130 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:51.507\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 41 semantic chunks from 130 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:51.508\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 8670\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:51.509\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 138 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:51.515\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 46 semantic chunks from 138 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:51.515\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 8341\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:51.516\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 128 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:51.522\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 47 semantic chunks from 128 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:51.522\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 8531\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:51.523\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 134 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:51.529\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 46 semantic chunks from 134 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:51.530\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 8620\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:51.531\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 139 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:51.537\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 44 semantic chunks from 139 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:51.538\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 8254\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:51.539\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 130 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:51.545\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 42 semantic chunks from 130 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:51.545\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 7984\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:51.546\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 130 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:51.552\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 46 semantic chunks from 130 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:51.553\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 8060\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:51.554\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 127 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:51.560\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 44 semantic chunks from 127 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:51.560\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 8513\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:51.561\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 127 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:51.567\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 50 semantic chunks from 127 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:51.568\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 8289\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:51.569\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 131 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:51.574\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 47 semantic chunks from 131 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:51.575\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 8402\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:51.576\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 129 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:51.582\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 47 semantic chunks from 129 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:51.583\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 8702\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:51.584\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 135 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:51.590\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 49 semantic chunks from 135 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:51.591\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 8654\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:51.592\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 137 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:51.598\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 54 semantic chunks from 137 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:51.598\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 8609\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:51.599\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 134 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:51.604\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 49 semantic chunks from 134 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:51.605\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 7529\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:51.606\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 117 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:51.612\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 41 semantic chunks from 117 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:51.612\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 8394\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:51.613\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 133 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:51.619\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 42 semantic chunks from 133 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:51.620\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 8884\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:51.621\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 137 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:51.627\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 49 semantic chunks from 137 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:51.628\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 8531\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:51.629\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 133 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:51.635\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 51 semantic chunks from 133 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:51.635\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 8731\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:51.636\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 137 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:51.642\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 51 semantic chunks from 137 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:51.642\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 8292\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:51.643\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 135 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:51.649\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 41 semantic chunks from 135 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:51.650\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 8796\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:51.651\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 139 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:51.657\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 52 semantic chunks from 139 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:51.657\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 8895\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:51.658\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 140 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:51.664\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 48 semantic chunks from 140 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:51.665\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 8071\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:51.666\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 127 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:51.672\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 43 semantic chunks from 127 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:51.672\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 8098\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:51.673\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 126 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:51.679\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 40 semantic chunks from 126 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:51.680\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 8492\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:51.681\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 133 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:51.687\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 43 semantic chunks from 133 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:51.688\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 8398\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:51.689\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 134 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:51.694\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 43 semantic chunks from 134 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:51.695\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 8898\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:51.696\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 142 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:51.702\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 55 semantic chunks from 142 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:51.703\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 8730\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:51.704\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 137 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:51.710\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 46 semantic chunks from 137 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:51.710\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 8211\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:51.711\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 132 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:51.717\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 40 semantic chunks from 132 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:51.718\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 7860\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:51.719\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 126 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:51.724\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 44 semantic chunks from 126 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:51.725\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 9010\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:51.726\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 141 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:51.732\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 50 semantic chunks from 141 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:51.732\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 8750\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:51.733\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 138 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:51.739\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 46 semantic chunks from 138 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:51.739\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 8318\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:51.740\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 134 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:51.746\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 45 semantic chunks from 134 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:51.747\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 7732\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:51.748\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 123 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:51.754\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 42 semantic chunks from 123 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:51.754\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 8606\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:51.755\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 137 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:51.761\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 46 semantic chunks from 137 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:51.762\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 8625\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:51.763\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 136 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:51.769\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 49 semantic chunks from 136 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:51.769\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 8899\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:51.770\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 141 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:51.775\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 50 semantic chunks from 141 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:51.776\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 8490\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:51.777\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 133 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:51.783\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 50 semantic chunks from 133 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:51.784\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 8922\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:51.785\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 136 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:51.791\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 48 semantic chunks from 136 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:51.792\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 8413\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:51.793\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 134 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:51.799\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 46 semantic chunks from 134 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:51.800\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 5008\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:51.800\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 97 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:51.805\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 33 semantic chunks from 97 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:51.805\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 3881\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:51.806\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 70 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:51.809\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 25 semantic chunks from 70 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:51.810\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 5418\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:51.810\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 126 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:51.816\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 38 semantic chunks from 126 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:51.816\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 5169\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:51.817\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 184 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:51.823\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 46 semantic chunks from 184 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:51.823\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.refinery.overlap\u001B[0m:\u001B[36mrefine\u001B[0m:\u001B[36m456\u001B[0m - \u001B[34m\u001B[1mStarting overlap refinery for 2087 chunks with method=suffix, mode=token\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:51.848\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.refinery.overlap\u001B[0m:\u001B[36mrefine\u001B[0m:\u001B[36m481\u001B[0m - \u001B[1mOverlap refinement complete: added context to 2087 chunks\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:51.848\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.refinery.embedding\u001B[0m:\u001B[36mrefine\u001B[0m:\u001B[36m51\u001B[0m - \u001B[34m\u001B[1mStarting embedding refinery for 2087 chunks\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:51.928\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.refinery.embedding\u001B[0m:\u001B[36mrefine\u001B[0m:\u001B[36m56\u001B[0m - \u001B[1mEmbedding refinement complete: added embeddings to 2087 chunks\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:54.574\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.recursive\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m368\u001B[0m - \u001B[34m\u001B[1mStarting recursive chunking for text of length 380241\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:54.664\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.recursive\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m370\u001B[0m - \u001B[1mCreated 44 chunks using recursive chunking\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:54.664\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 8424\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:54.665\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 143 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:54.672\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 53 semantic chunks from 143 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:54.673\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 8811\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:54.674\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 140 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:54.680\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 47 semantic chunks from 140 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:54.680\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 8996\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:54.682\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 144 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:54.688\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 58 semantic chunks from 144 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:54.688\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 9512\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:54.689\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 152 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:54.696\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 50 semantic chunks from 152 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:54.697\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 9004\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:54.698\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 142 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:54.704\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 52 semantic chunks from 142 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:54.704\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 9318\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:54.706\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 145 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:54.712\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 46 semantic chunks from 145 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:54.713\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 9272\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:54.714\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 145 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:54.720\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 53 semantic chunks from 145 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:54.721\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 9177\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:54.722\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 143 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:54.728\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 51 semantic chunks from 143 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:54.728\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 8915\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:54.729\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 142 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:54.736\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 53 semantic chunks from 142 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:54.736\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 8799\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:54.737\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 139 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:54.743\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 49 semantic chunks from 139 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:54.744\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 8834\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:54.745\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 141 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:54.751\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 50 semantic chunks from 141 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:54.752\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 9088\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:54.753\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 145 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:54.759\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 52 semantic chunks from 145 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:54.759\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 8942\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:54.760\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 140 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:54.766\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 46 semantic chunks from 140 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:54.767\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 8807\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:54.768\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 144 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:54.774\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 53 semantic chunks from 144 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:54.774\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 9086\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:54.775\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 144 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:54.781\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 48 semantic chunks from 144 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:54.782\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 8710\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:54.783\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 136 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:54.789\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 54 semantic chunks from 136 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:54.790\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 8549\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:54.791\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 135 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:54.798\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 46 semantic chunks from 135 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:54.799\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 8830\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:54.800\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 141 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:54.806\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 48 semantic chunks from 141 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:54.806\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 9332\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:54.807\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 144 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:54.814\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 54 semantic chunks from 144 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:54.814\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 9279\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:54.815\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 145 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:54.821\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 54 semantic chunks from 145 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:54.821\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 9679\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:54.822\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 149 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:54.842\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 60 semantic chunks from 149 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:54.843\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 9134\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:54.844\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 143 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:54.849\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 50 semantic chunks from 143 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:54.850\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 9167\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:54.851\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 146 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:54.857\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 46 semantic chunks from 146 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:54.858\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 9318\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:54.859\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 143 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:54.864\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 54 semantic chunks from 143 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:54.865\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 9307\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:54.866\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 143 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:54.871\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 50 semantic chunks from 143 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:54.872\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 9306\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:54.873\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 144 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:54.878\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 50 semantic chunks from 144 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:54.879\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 9453\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:54.880\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 148 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:54.887\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 57 semantic chunks from 148 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:54.887\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 9443\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:54.888\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 146 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:54.894\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 54 semantic chunks from 146 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:54.895\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 9505\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:54.896\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 151 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:54.903\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 56 semantic chunks from 151 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:54.903\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 9218\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:54.904\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 144 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:54.910\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 53 semantic chunks from 144 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:54.911\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 9426\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:54.912\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 145 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:54.918\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 58 semantic chunks from 145 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:54.919\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 9427\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:54.920\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 145 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:54.926\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 49 semantic chunks from 145 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:54.927\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 8971\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:54.928\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 146 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:54.934\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 53 semantic chunks from 146 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:54.935\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 9236\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:54.936\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 146 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:54.942\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 55 semantic chunks from 146 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:54.943\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 8753\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:54.944\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 142 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:54.950\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 51 semantic chunks from 142 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:54.950\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 8889\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:54.951\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 144 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:54.958\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 50 semantic chunks from 144 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:54.958\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 9123\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:54.959\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 130 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:54.966\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 45 semantic chunks from 130 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:54.966\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 8510\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:54.967\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 128 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:54.976\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 38 semantic chunks from 128 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:54.977\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 8904\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:54.978\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 133 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:54.983\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 43 semantic chunks from 133 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:54.984\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 8883\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:54.985\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 139 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:54.991\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 50 semantic chunks from 139 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:54.991\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 7235\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:54.992\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 133 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:54.998\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 45 semantic chunks from 133 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:54.999\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 4370\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:55.000\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 139 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:55.005\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 40 semantic chunks from 139 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:55.006\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 4453\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:55.007\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 147 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:55.012\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 34 semantic chunks from 147 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:55.013\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 846\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:55.013\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 29 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:55.015\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 8 semantic chunks from 29 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:55.015\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.refinery.overlap\u001B[0m:\u001B[36mrefine\u001B[0m:\u001B[36m456\u001B[0m - \u001B[34m\u001B[1mStarting overlap refinery for 2166 chunks with method=suffix, mode=token\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:55.042\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.refinery.overlap\u001B[0m:\u001B[36mrefine\u001B[0m:\u001B[36m481\u001B[0m - \u001B[1mOverlap refinement complete: added context to 2166 chunks\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:55.043\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.refinery.embedding\u001B[0m:\u001B[36mrefine\u001B[0m:\u001B[36m51\u001B[0m - \u001B[34m\u001B[1mStarting embedding refinery for 2166 chunks\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:55.114\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.refinery.embedding\u001B[0m:\u001B[36mrefine\u001B[0m:\u001B[36m56\u001B[0m - \u001B[1mEmbedding refinement complete: added embeddings to 2166 chunks\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:56.305\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.recursive\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m368\u001B[0m - \u001B[34m\u001B[1mStarting recursive chunking for text of length 148058\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:56.344\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.recursive\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m370\u001B[0m - \u001B[1mCreated 18 chunks using recursive chunking\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:56.344\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 8033\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:56.345\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 132 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:56.352\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 50 semantic chunks from 132 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:56.352\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 8525\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:56.353\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 136 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:56.360\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 52 semantic chunks from 136 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:56.360\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 7433\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:56.361\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 120 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:56.367\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 39 semantic chunks from 120 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:56.367\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 8942\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:56.369\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 142 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:56.375\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 51 semantic chunks from 142 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:56.375\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 9005\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:56.377\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 141 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:56.383\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 44 semantic chunks from 141 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:56.383\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 8821\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:56.385\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 144 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:56.391\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 48 semantic chunks from 144 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:56.391\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 8387\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:56.392\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 135 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:56.398\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 53 semantic chunks from 135 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:56.399\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 8654\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:56.400\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 143 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:56.405\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 46 semantic chunks from 143 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:56.406\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 9287\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:56.407\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 147 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:56.414\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 51 semantic chunks from 147 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:56.414\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 9023\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:56.416\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 139 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:56.422\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 46 semantic chunks from 139 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:56.422\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 8895\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:56.424\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 143 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:56.429\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 42 semantic chunks from 143 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:56.430\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 9271\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:56.431\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 148 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:56.438\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 56 semantic chunks from 148 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:56.438\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 9108\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:56.439\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 143 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:56.445\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 53 semantic chunks from 143 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:56.446\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 8725\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:56.447\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 135 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:56.453\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 47 semantic chunks from 135 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:56.453\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 7966\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:56.454\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 123 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:56.460\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 43 semantic chunks from 123 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:56.460\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 7943\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:56.461\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 80 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:56.466\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 23 semantic chunks from 80 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:56.466\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 7279\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:56.467\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 77 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:56.472\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 22 semantic chunks from 77 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:56.472\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 2761\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:56.473\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 84 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:56.477\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 24 semantic chunks from 84 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:56.477\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.refinery.overlap\u001B[0m:\u001B[36mrefine\u001B[0m:\u001B[36m456\u001B[0m - \u001B[34m\u001B[1mStarting overlap refinery for 790 chunks with method=suffix, mode=token\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:56.487\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.refinery.overlap\u001B[0m:\u001B[36mrefine\u001B[0m:\u001B[36m481\u001B[0m - \u001B[1mOverlap refinement complete: added context to 790 chunks\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:56.488\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.refinery.embedding\u001B[0m:\u001B[36mrefine\u001B[0m:\u001B[36m51\u001B[0m - \u001B[34m\u001B[1mStarting embedding refinery for 790 chunks\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:56.518\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.refinery.embedding\u001B[0m:\u001B[36mrefine\u001B[0m:\u001B[36m56\u001B[0m - \u001B[1mEmbedding refinement complete: added embeddings to 790 chunks\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:56.879\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.recursive\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m368\u001B[0m - \u001B[34m\u001B[1mStarting recursive chunking for text of length 47331\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:56.892\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.recursive\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m370\u001B[0m - \u001B[1mCreated 6 chunks using recursive chunking\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:56.893\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 7991\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:56.894\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 130 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:56.900\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 45 semantic chunks from 130 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:56.901\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 8534\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:56.902\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 144 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:56.908\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 46 semantic chunks from 144 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:56.909\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 7878\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:56.910\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 130 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:56.916\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 46 semantic chunks from 130 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:56.917\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 8430\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:56.918\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 138 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:56.924\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 45 semantic chunks from 138 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:56.924\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 7904\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:56.925\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 137 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:56.931\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 47 semantic chunks from 137 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:56.932\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 6594\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:56.933\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 114 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:56.937\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 35 semantic chunks from 114 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:56.938\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.refinery.overlap\u001B[0m:\u001B[36mrefine\u001B[0m:\u001B[36m456\u001B[0m - \u001B[34m\u001B[1mStarting overlap refinery for 264 chunks with method=suffix, mode=token\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:56.941\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.refinery.overlap\u001B[0m:\u001B[36mrefine\u001B[0m:\u001B[36m481\u001B[0m - \u001B[1mOverlap refinement complete: added context to 264 chunks\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:56.941\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.refinery.embedding\u001B[0m:\u001B[36mrefine\u001B[0m:\u001B[36m51\u001B[0m - \u001B[34m\u001B[1mStarting embedding refinery for 264 chunks\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:56.951\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.refinery.embedding\u001B[0m:\u001B[36mrefine\u001B[0m:\u001B[36m56\u001B[0m - \u001B[1mEmbedding refinement complete: added embeddings to 264 chunks\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:57.328\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.recursive\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m368\u001B[0m - \u001B[34m\u001B[1mStarting recursive chunking for text of length 49678\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:57.340\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.recursive\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m370\u001B[0m - \u001B[1mCreated 6 chunks using recursive chunking\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:57.341\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 7249\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:57.342\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 130 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:57.348\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 40 semantic chunks from 130 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:57.349\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 9435\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:57.350\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 149 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:57.356\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 50 semantic chunks from 149 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:57.356\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 8862\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:57.357\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 143 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:57.363\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 47 semantic chunks from 143 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:57.363\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 8700\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:57.364\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 139 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:57.369\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 51 semantic chunks from 139 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:57.370\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 8095\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:57.371\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 136 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:57.376\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 39 semantic chunks from 136 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:57.377\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 7337\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:57.377\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 132 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:57.382\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 44 semantic chunks from 132 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:57.383\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.refinery.overlap\u001B[0m:\u001B[36mrefine\u001B[0m:\u001B[36m456\u001B[0m - \u001B[34m\u001B[1mStarting overlap refinery for 271 chunks with method=suffix, mode=token\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:57.386\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.refinery.overlap\u001B[0m:\u001B[36mrefine\u001B[0m:\u001B[36m481\u001B[0m - \u001B[1mOverlap refinement complete: added context to 271 chunks\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:57.386\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.refinery.embedding\u001B[0m:\u001B[36mrefine\u001B[0m:\u001B[36m51\u001B[0m - \u001B[34m\u001B[1mStarting embedding refinery for 271 chunks\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:57.397\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.refinery.embedding\u001B[0m:\u001B[36mrefine\u001B[0m:\u001B[36m56\u001B[0m - \u001B[1mEmbedding refinement complete: added embeddings to 271 chunks\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:58.743\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.recursive\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m368\u001B[0m - \u001B[34m\u001B[1mStarting recursive chunking for text of length 206174\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:58.798\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.recursive\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m370\u001B[0m - \u001B[1mCreated 25 chunks using recursive chunking\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:58.798\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 7579\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:58.799\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 128 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:58.805\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 38 semantic chunks from 128 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:58.806\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 8479\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:58.807\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 135 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:58.813\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 47 semantic chunks from 135 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:58.813\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 8585\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:58.814\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 133 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:58.821\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 45 semantic chunks from 133 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:58.821\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 8518\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:58.823\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 140 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:58.828\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 43 semantic chunks from 140 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:58.829\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 8223\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:58.830\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 136 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:58.836\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 45 semantic chunks from 136 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:58.836\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 8170\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:58.838\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 135 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:58.843\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 50 semantic chunks from 135 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:58.844\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 8392\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:58.845\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 126 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:58.851\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 48 semantic chunks from 126 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:58.851\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 8531\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:58.852\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 133 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:58.858\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 49 semantic chunks from 133 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:58.858\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 8555\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:58.859\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 133 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:58.866\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 41 semantic chunks from 133 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:58.867\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 8501\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:58.868\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 137 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:58.873\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 44 semantic chunks from 137 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:58.874\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 8512\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:58.875\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 130 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:58.881\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 46 semantic chunks from 130 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:58.882\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 8416\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:58.883\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 126 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:58.889\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 42 semantic chunks from 126 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:58.890\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 8602\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:58.891\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 135 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:58.897\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 46 semantic chunks from 135 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:58.898\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 8388\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:58.899\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 134 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:58.904\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 54 semantic chunks from 134 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:58.905\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 8060\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:58.906\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 121 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:58.912\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 41 semantic chunks from 121 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:58.912\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 8375\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:58.913\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 137 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:58.920\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 46 semantic chunks from 137 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:58.921\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 8462\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:58.922\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 134 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:58.928\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 43 semantic chunks from 134 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:58.928\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 8098\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:58.929\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 131 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:58.935\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 42 semantic chunks from 131 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:58.935\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 8415\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:58.936\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 132 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:58.944\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 50 semantic chunks from 132 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:58.945\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 8163\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:58.946\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 140 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:58.952\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 36 semantic chunks from 140 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:58.952\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 7603\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:58.953\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 123 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:58.959\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 42 semantic chunks from 123 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:58.960\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 8084\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:58.961\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 134 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:58.967\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 50 semantic chunks from 134 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:58.967\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 8011\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:58.968\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 126 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:58.974\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 38 semantic chunks from 126 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:58.975\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 7882\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:58.976\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 142 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:58.982\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 50 semantic chunks from 142 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:58.982\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 7570\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:58.983\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 123 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:58.989\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 42 semantic chunks from 123 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:58.989\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.refinery.overlap\u001B[0m:\u001B[36mrefine\u001B[0m:\u001B[36m456\u001B[0m - \u001B[34m\u001B[1mStarting overlap refinery for 1118 chunks with method=suffix, mode=token\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:59.004\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.refinery.overlap\u001B[0m:\u001B[36mrefine\u001B[0m:\u001B[36m481\u001B[0m - \u001B[1mOverlap refinement complete: added context to 1118 chunks\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:59.004\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.refinery.embedding\u001B[0m:\u001B[36mrefine\u001B[0m:\u001B[36m51\u001B[0m - \u001B[34m\u001B[1mStarting embedding refinery for 1118 chunks\u001B[0m\n",
      "\u001B[32m2025-11-09 20:16:59.048\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.refinery.embedding\u001B[0m:\u001B[36mrefine\u001B[0m:\u001B[36m56\u001B[0m - \u001B[1mEmbedding refinement complete: added embeddings to 1118 chunks\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:00.451\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.recursive\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m368\u001B[0m - \u001B[34m\u001B[1mStarting recursive chunking for text of length 210298\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:00.503\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.recursive\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m370\u001B[0m - \u001B[1mCreated 25 chunks using recursive chunking\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:00.504\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 7963\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:00.505\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 131 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:00.511\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 49 semantic chunks from 131 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:00.511\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 8089\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:00.513\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 136 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:00.519\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 46 semantic chunks from 136 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:00.519\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 8430\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:00.520\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 128 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:00.527\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 42 semantic chunks from 128 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:00.527\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 9100\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:00.528\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 140 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:00.534\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 45 semantic chunks from 140 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:00.535\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 8710\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:00.536\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 140 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:00.542\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 43 semantic chunks from 140 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:00.543\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 8276\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:00.544\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 137 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:00.550\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 46 semantic chunks from 137 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:00.550\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 8175\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:00.551\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 129 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:00.557\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 46 semantic chunks from 129 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:00.558\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 8887\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:00.559\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 141 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:00.565\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 58 semantic chunks from 141 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:00.565\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 8725\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:00.566\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 135 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:00.572\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 50 semantic chunks from 135 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:00.572\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 8670\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:00.573\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 138 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:00.579\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 52 semantic chunks from 138 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:00.580\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 8101\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:00.581\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 129 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:00.587\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 46 semantic chunks from 129 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:00.588\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 8508\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:00.589\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 135 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:00.595\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 48 semantic chunks from 135 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:00.596\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 8746\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:00.597\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 148 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:00.603\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 46 semantic chunks from 148 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:00.604\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 8527\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:00.605\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 133 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:00.611\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 48 semantic chunks from 133 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:00.611\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 8594\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:00.612\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 135 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:00.618\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 53 semantic chunks from 135 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:00.619\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 8877\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:00.620\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 141 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:00.626\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 50 semantic chunks from 141 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:00.627\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 8649\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:00.628\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 135 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:00.634\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 42 semantic chunks from 135 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:00.634\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 9023\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:00.636\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 139 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:00.642\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 50 semantic chunks from 139 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:00.642\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 8851\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:00.644\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 135 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:00.649\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 44 semantic chunks from 135 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:00.650\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 8237\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:00.651\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 138 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:00.657\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 46 semantic chunks from 138 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:00.657\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 8468\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:00.658\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 135 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:00.663\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 46 semantic chunks from 135 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:00.664\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 8409\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:00.665\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 138 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:00.671\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 48 semantic chunks from 138 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:00.672\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 8414\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:00.673\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 131 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:00.679\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 46 semantic chunks from 131 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:00.680\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 8115\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:00.681\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 133 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:00.687\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 43 semantic chunks from 133 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:00.687\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 5754\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:00.688\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 94 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:00.692\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 35 semantic chunks from 94 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:00.693\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.refinery.overlap\u001B[0m:\u001B[36mrefine\u001B[0m:\u001B[36m456\u001B[0m - \u001B[34m\u001B[1mStarting overlap refinery for 1168 chunks with method=suffix, mode=token\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:00.707\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.refinery.overlap\u001B[0m:\u001B[36mrefine\u001B[0m:\u001B[36m481\u001B[0m - \u001B[1mOverlap refinement complete: added context to 1168 chunks\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:00.707\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.refinery.embedding\u001B[0m:\u001B[36mrefine\u001B[0m:\u001B[36m51\u001B[0m - \u001B[34m\u001B[1mStarting embedding refinery for 1168 chunks\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:00.754\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.refinery.embedding\u001B[0m:\u001B[36mrefine\u001B[0m:\u001B[36m56\u001B[0m - \u001B[1mEmbedding refinement complete: added embeddings to 1168 chunks\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:01.312\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.recursive\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m368\u001B[0m - \u001B[34m\u001B[1mStarting recursive chunking for text of length 73053\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:01.331\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.recursive\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m370\u001B[0m - \u001B[1mCreated 9 chunks using recursive chunking\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:01.331\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 7849\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:01.332\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 131 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:01.339\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 42 semantic chunks from 131 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:01.339\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 9003\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:01.341\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 142 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:01.347\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 49 semantic chunks from 142 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:01.348\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 9099\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:01.349\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 150 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:01.355\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 50 semantic chunks from 150 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:01.356\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 9122\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:01.357\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 147 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:01.363\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 51 semantic chunks from 147 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:01.364\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 9424\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:01.365\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 150 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:01.371\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 50 semantic chunks from 150 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:01.371\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 9118\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:01.372\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 144 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:01.378\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 46 semantic chunks from 144 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:01.379\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 9142\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:01.380\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 146 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:01.386\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 51 semantic chunks from 146 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:01.386\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 7372\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:01.387\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 117 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:01.393\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 46 semantic chunks from 117 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:01.393\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 2924\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:01.394\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 44 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:01.396\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 15 semantic chunks from 44 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:01.397\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.refinery.overlap\u001B[0m:\u001B[36mrefine\u001B[0m:\u001B[36m456\u001B[0m - \u001B[34m\u001B[1mStarting overlap refinery for 400 chunks with method=suffix, mode=token\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:01.402\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.refinery.overlap\u001B[0m:\u001B[36mrefine\u001B[0m:\u001B[36m481\u001B[0m - \u001B[1mOverlap refinement complete: added context to 400 chunks\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:01.402\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.refinery.embedding\u001B[0m:\u001B[36mrefine\u001B[0m:\u001B[36m51\u001B[0m - \u001B[34m\u001B[1mStarting embedding refinery for 400 chunks\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:01.415\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.refinery.embedding\u001B[0m:\u001B[36mrefine\u001B[0m:\u001B[36m56\u001B[0m - \u001B[1mEmbedding refinement complete: added embeddings to 400 chunks\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:01.951\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.recursive\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m368\u001B[0m - \u001B[34m\u001B[1mStarting recursive chunking for text of length 73800\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:01.970\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.recursive\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m370\u001B[0m - \u001B[1mCreated 9 chunks using recursive chunking\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:01.971\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 7827\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:01.972\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 129 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:01.978\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 46 semantic chunks from 129 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:01.979\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 8641\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:01.980\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 135 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:01.987\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 53 semantic chunks from 135 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:01.987\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 8643\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:01.989\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 136 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:01.994\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 44 semantic chunks from 136 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:01.995\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 8701\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:01.996\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 139 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:02.002\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 52 semantic chunks from 139 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:02.002\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 8396\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:02.004\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 138 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:02.009\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 50 semantic chunks from 138 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:02.009\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 8571\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:02.011\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 143 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:02.016\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 50 semantic chunks from 143 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:02.017\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 7499\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:02.018\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 131 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:02.023\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 47 semantic chunks from 131 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:02.024\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 8691\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:02.025\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 143 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:02.031\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 54 semantic chunks from 143 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:02.031\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 6831\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:02.032\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 133 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:02.038\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 42 semantic chunks from 133 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:02.038\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.refinery.overlap\u001B[0m:\u001B[36mrefine\u001B[0m:\u001B[36m456\u001B[0m - \u001B[34m\u001B[1mStarting overlap refinery for 438 chunks with method=suffix, mode=token\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:02.043\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.refinery.overlap\u001B[0m:\u001B[36mrefine\u001B[0m:\u001B[36m481\u001B[0m - \u001B[1mOverlap refinement complete: added context to 438 chunks\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:02.044\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.refinery.embedding\u001B[0m:\u001B[36mrefine\u001B[0m:\u001B[36m51\u001B[0m - \u001B[34m\u001B[1mStarting embedding refinery for 438 chunks\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:02.057\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.refinery.embedding\u001B[0m:\u001B[36mrefine\u001B[0m:\u001B[36m56\u001B[0m - \u001B[1mEmbedding refinement complete: added embeddings to 438 chunks\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:02.776\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.recursive\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m368\u001B[0m - \u001B[34m\u001B[1mStarting recursive chunking for text of length 104198\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:02.804\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.recursive\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m370\u001B[0m - \u001B[1mCreated 14 chunks using recursive chunking\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:02.805\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 7079\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:02.806\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 126 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:02.812\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 45 semantic chunks from 126 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:02.812\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 7760\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:02.813\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 128 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:02.819\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 39 semantic chunks from 128 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:02.820\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 8129\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:02.821\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 130 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:02.827\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 46 semantic chunks from 130 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:02.828\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 8144\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:02.829\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 135 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:02.835\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 46 semantic chunks from 135 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:02.836\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 6755\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:02.837\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 114 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:02.841\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 43 semantic chunks from 114 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:02.842\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 8195\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:02.843\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 130 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:02.850\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 43 semantic chunks from 130 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:02.850\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 8138\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:02.852\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 128 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:02.858\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 43 semantic chunks from 128 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:02.858\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 8451\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:02.859\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 143 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:02.865\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 43 semantic chunks from 143 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:02.866\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 8374\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:02.867\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 140 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:02.880\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 50 semantic chunks from 140 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:02.881\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 8954\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:02.882\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 143 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:02.889\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 47 semantic chunks from 143 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:02.889\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 8648\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:02.891\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 139 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:02.896\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 54 semantic chunks from 139 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:02.897\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 7865\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:02.898\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 131 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:02.904\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 47 semantic chunks from 131 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:02.904\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 4927\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:02.905\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 124 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:02.911\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 42 semantic chunks from 124 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:02.912\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 2779\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:02.912\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 87 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:02.916\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 29 semantic chunks from 87 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:02.917\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.refinery.overlap\u001B[0m:\u001B[36mrefine\u001B[0m:\u001B[36m456\u001B[0m - \u001B[34m\u001B[1mStarting overlap refinery for 617 chunks with method=suffix, mode=token\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:02.925\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.refinery.overlap\u001B[0m:\u001B[36mrefine\u001B[0m:\u001B[36m481\u001B[0m - \u001B[1mOverlap refinement complete: added context to 617 chunks\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:02.925\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.refinery.embedding\u001B[0m:\u001B[36mrefine\u001B[0m:\u001B[36m51\u001B[0m - \u001B[34m\u001B[1mStarting embedding refinery for 617 chunks\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:02.952\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.refinery.embedding\u001B[0m:\u001B[36mrefine\u001B[0m:\u001B[36m56\u001B[0m - \u001B[1mEmbedding refinement complete: added embeddings to 617 chunks\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:04.010\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.recursive\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m368\u001B[0m - \u001B[34m\u001B[1mStarting recursive chunking for text of length 153747\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:04.048\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.recursive\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m370\u001B[0m - \u001B[1mCreated 19 chunks using recursive chunking\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:04.049\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 7966\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:04.050\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 132 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:04.056\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 47 semantic chunks from 132 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:04.057\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 8409\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:04.058\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 141 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:04.064\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 51 semantic chunks from 141 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:04.065\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 8238\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:04.066\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 130 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:04.071\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 49 semantic chunks from 130 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:04.072\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 8382\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:04.073\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 142 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:04.079\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 47 semantic chunks from 142 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:04.080\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 8481\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:04.081\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 136 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:04.087\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 50 semantic chunks from 136 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:04.087\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 8700\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:04.088\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 143 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:04.095\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 48 semantic chunks from 143 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:04.096\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 8432\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:04.097\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 135 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:04.103\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 42 semantic chunks from 135 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:04.104\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 8663\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:04.105\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 135 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:04.111\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 50 semantic chunks from 135 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:04.112\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 8637\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:04.113\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 140 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:04.118\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 46 semantic chunks from 140 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:04.119\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 8415\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:04.120\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 135 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:04.125\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 50 semantic chunks from 135 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:04.126\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 8463\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:04.127\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 134 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:04.132\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 53 semantic chunks from 134 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:04.133\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 8613\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:04.134\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 138 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:04.139\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 42 semantic chunks from 138 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:04.140\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 8547\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:04.141\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 133 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:04.147\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 43 semantic chunks from 133 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:04.148\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 9043\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:04.149\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 139 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:04.155\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 54 semantic chunks from 139 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:04.156\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 7908\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:04.157\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 127 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:04.162\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 46 semantic chunks from 127 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:04.163\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 8249\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:04.164\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 135 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:04.169\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 44 semantic chunks from 135 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:04.169\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 8224\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:04.170\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 130 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:04.176\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 42 semantic chunks from 130 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:04.176\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 8323\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:04.178\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 138 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:04.184\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 46 semantic chunks from 138 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:04.185\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 2054\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:04.185\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 40 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:04.187\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 15 semantic chunks from 40 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:04.188\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.refinery.overlap\u001B[0m:\u001B[36mrefine\u001B[0m:\u001B[36m456\u001B[0m - \u001B[34m\u001B[1mStarting overlap refinery for 865 chunks with method=suffix, mode=token\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:04.198\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.refinery.overlap\u001B[0m:\u001B[36mrefine\u001B[0m:\u001B[36m481\u001B[0m - \u001B[1mOverlap refinement complete: added context to 865 chunks\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:04.198\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.refinery.embedding\u001B[0m:\u001B[36mrefine\u001B[0m:\u001B[36m51\u001B[0m - \u001B[34m\u001B[1mStarting embedding refinery for 865 chunks\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:04.228\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.refinery.embedding\u001B[0m:\u001B[36mrefine\u001B[0m:\u001B[36m56\u001B[0m - \u001B[1mEmbedding refinement complete: added embeddings to 865 chunks\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:05.063\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.recursive\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m368\u001B[0m - \u001B[34m\u001B[1mStarting recursive chunking for text of length 120655\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:05.092\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.recursive\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m370\u001B[0m - \u001B[1mCreated 15 chunks using recursive chunking\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:05.093\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 7831\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:05.094\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 127 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:05.101\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 48 semantic chunks from 127 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:05.101\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 8000\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:05.102\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 124 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:05.108\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 42 semantic chunks from 124 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:05.109\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 8275\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:05.110\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 129 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:05.116\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 48 semantic chunks from 129 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:05.117\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 9216\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:05.118\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 146 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:05.124\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 55 semantic chunks from 146 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:05.125\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 9051\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:05.126\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 139 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:05.132\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 52 semantic chunks from 139 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:05.133\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 8886\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:05.134\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 142 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:05.141\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 50 semantic chunks from 142 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:05.141\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 9043\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:05.142\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 144 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:05.148\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 50 semantic chunks from 144 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:05.149\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 8679\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:05.150\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 140 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:05.156\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 55 semantic chunks from 140 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:05.157\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 9207\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:05.158\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 146 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:05.164\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 47 semantic chunks from 146 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:05.165\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 8759\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:05.166\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 135 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:05.172\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 46 semantic chunks from 135 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:05.172\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 8085\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:05.173\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 137 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:05.179\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 46 semantic chunks from 137 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:05.180\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 6912\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:05.181\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 103 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:05.187\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 37 semantic chunks from 103 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:05.188\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 7108\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:05.189\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 106 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:05.195\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 40 semantic chunks from 106 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:05.196\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 6859\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:05.197\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 100 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:05.203\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 35 semantic chunks from 100 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:05.203\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 4744\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:05.204\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 116 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:05.209\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 34 semantic chunks from 116 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:05.210\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.refinery.overlap\u001B[0m:\u001B[36mrefine\u001B[0m:\u001B[36m456\u001B[0m - \u001B[34m\u001B[1mStarting overlap refinery for 685 chunks with method=suffix, mode=token\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:05.218\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.refinery.overlap\u001B[0m:\u001B[36mrefine\u001B[0m:\u001B[36m481\u001B[0m - \u001B[1mOverlap refinement complete: added context to 685 chunks\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:05.218\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.refinery.embedding\u001B[0m:\u001B[36mrefine\u001B[0m:\u001B[36m51\u001B[0m - \u001B[34m\u001B[1mStarting embedding refinery for 685 chunks\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:05.244\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.refinery.embedding\u001B[0m:\u001B[36mrefine\u001B[0m:\u001B[36m56\u001B[0m - \u001B[1mEmbedding refinement complete: added embeddings to 685 chunks\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:06.478\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.recursive\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m368\u001B[0m - \u001B[34m\u001B[1mStarting recursive chunking for text of length 179618\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:06.524\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.recursive\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m370\u001B[0m - \u001B[1mCreated 24 chunks using recursive chunking\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:06.525\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 7290\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:06.526\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 123 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:06.532\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 48 semantic chunks from 123 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:06.532\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 7395\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:06.534\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 113 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:06.539\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 37 semantic chunks from 113 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:06.539\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 7775\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:06.541\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 124 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:06.546\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 44 semantic chunks from 124 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:06.547\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 7554\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:06.548\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 124 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:06.554\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 39 semantic chunks from 124 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:06.554\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 7857\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:06.555\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 121 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:06.561\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 43 semantic chunks from 121 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:06.561\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 7651\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:06.563\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 132 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:06.569\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 42 semantic chunks from 132 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:06.569\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 7646\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:06.571\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 121 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:06.577\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 40 semantic chunks from 121 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:06.577\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 8691\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:06.578\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 136 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:06.584\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 53 semantic chunks from 136 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:06.585\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 8267\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:06.586\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 137 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:06.592\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 50 semantic chunks from 137 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:06.592\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 7981\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:06.593\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 127 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:06.599\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 43 semantic chunks from 127 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:06.600\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 8493\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:06.601\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 137 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:06.606\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 47 semantic chunks from 137 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:06.607\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 8988\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:06.608\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 142 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:06.614\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 52 semantic chunks from 142 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:06.614\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 8421\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:06.616\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 132 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:06.621\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 42 semantic chunks from 132 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:06.622\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 7788\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:06.623\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 125 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:06.629\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 47 semantic chunks from 125 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:06.629\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 6969\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:06.630\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 125 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:06.636\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 46 semantic chunks from 125 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:06.636\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 6797\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:06.638\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 119 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:06.642\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 42 semantic chunks from 119 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:06.643\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 6887\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:06.644\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 115 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:06.650\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 44 semantic chunks from 115 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:06.650\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 6627\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:06.651\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 121 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:06.657\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 42 semantic chunks from 121 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:06.657\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 6864\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:06.658\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 121 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:06.665\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 42 semantic chunks from 121 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:06.665\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 7407\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:06.667\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 122 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:06.672\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 49 semantic chunks from 122 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:06.673\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 7899\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:06.674\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 128 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:06.680\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 44 semantic chunks from 128 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:06.680\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 7547\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:06.681\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 122 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:06.687\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 42 semantic chunks from 122 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:06.687\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 8700\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:06.689\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 139 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:06.694\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 51 semantic chunks from 139 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:06.695\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 2124\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:06.695\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 33 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:06.697\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 10 semantic chunks from 33 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:06.698\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.refinery.overlap\u001B[0m:\u001B[36mrefine\u001B[0m:\u001B[36m456\u001B[0m - \u001B[34m\u001B[1mStarting overlap refinery for 1039 chunks with method=suffix, mode=token\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:06.710\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.refinery.overlap\u001B[0m:\u001B[36mrefine\u001B[0m:\u001B[36m481\u001B[0m - \u001B[1mOverlap refinement complete: added context to 1039 chunks\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:06.710\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.refinery.embedding\u001B[0m:\u001B[36mrefine\u001B[0m:\u001B[36m51\u001B[0m - \u001B[34m\u001B[1mStarting embedding refinery for 1039 chunks\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:06.750\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.refinery.embedding\u001B[0m:\u001B[36mrefine\u001B[0m:\u001B[36m56\u001B[0m - \u001B[1mEmbedding refinement complete: added embeddings to 1039 chunks\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:07.660\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.recursive\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m368\u001B[0m - \u001B[34m\u001B[1mStarting recursive chunking for text of length 131337\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:07.694\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.recursive\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m370\u001B[0m - \u001B[1mCreated 16 chunks using recursive chunking\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:07.694\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 7971\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:07.695\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 127 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:07.701\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 42 semantic chunks from 127 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:07.702\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 8785\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:07.703\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 143 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:07.708\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 50 semantic chunks from 143 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:07.708\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 9002\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:07.710\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 147 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:07.716\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 51 semantic chunks from 147 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:07.717\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 8687\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:07.718\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 135 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:07.725\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 52 semantic chunks from 135 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:07.725\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 8567\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:07.726\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 133 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:07.732\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 47 semantic chunks from 133 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:07.733\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 8445\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:07.734\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 132 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:07.739\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 49 semantic chunks from 132 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:07.740\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 8432\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:07.741\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 130 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:07.746\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 39 semantic chunks from 130 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:07.747\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 8686\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:07.748\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 137 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:07.754\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 48 semantic chunks from 137 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:07.754\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 8212\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:07.755\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 132 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:07.762\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 49 semantic chunks from 132 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:07.762\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 8385\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:07.763\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 129 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:07.769\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 47 semantic chunks from 129 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:07.770\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 8355\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:07.771\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 127 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:07.777\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 47 semantic chunks from 127 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:07.778\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 8834\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:07.778\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 128 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:07.784\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 51 semantic chunks from 128 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:07.785\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 8932\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:07.786\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 126 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:07.791\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 44 semantic chunks from 126 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:07.792\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 9000\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:07.793\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 131 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:07.799\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 37 semantic chunks from 131 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:07.799\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 8813\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:07.800\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 127 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:07.806\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 45 semantic chunks from 127 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:07.807\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 2231\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:07.807\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 34 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:07.810\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 12 semantic chunks from 34 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:07.810\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.refinery.overlap\u001B[0m:\u001B[36mrefine\u001B[0m:\u001B[36m456\u001B[0m - \u001B[34m\u001B[1mStarting overlap refinery for 710 chunks with method=suffix, mode=token\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:07.819\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.refinery.overlap\u001B[0m:\u001B[36mrefine\u001B[0m:\u001B[36m481\u001B[0m - \u001B[1mOverlap refinement complete: added context to 710 chunks\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:07.820\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.refinery.embedding\u001B[0m:\u001B[36mrefine\u001B[0m:\u001B[36m51\u001B[0m - \u001B[34m\u001B[1mStarting embedding refinery for 710 chunks\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:07.846\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.refinery.embedding\u001B[0m:\u001B[36mrefine\u001B[0m:\u001B[36m56\u001B[0m - \u001B[1mEmbedding refinement complete: added embeddings to 710 chunks\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:09.723\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.recursive\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m368\u001B[0m - \u001B[34m\u001B[1mStarting recursive chunking for text of length 276712\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:09.798\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.recursive\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m370\u001B[0m - \u001B[1mCreated 34 chunks using recursive chunking\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:09.799\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 7702\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:09.800\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 127 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:09.807\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 42 semantic chunks from 127 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:09.808\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 8721\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:09.809\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 140 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:09.815\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 54 semantic chunks from 140 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:09.816\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 8946\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:09.817\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 146 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:09.823\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 55 semantic chunks from 146 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:09.824\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 9039\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:09.825\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 146 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:09.831\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 56 semantic chunks from 146 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:09.832\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 8609\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:09.833\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 136 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:09.838\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 54 semantic chunks from 136 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:09.839\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 8501\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:09.840\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 137 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:09.845\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 46 semantic chunks from 137 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:09.846\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 8884\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:09.847\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 140 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:09.853\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 50 semantic chunks from 140 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:09.854\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 8861\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:09.855\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 139 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:09.862\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 44 semantic chunks from 139 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:09.862\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 8652\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:09.863\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 140 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:09.869\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 50 semantic chunks from 140 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:09.870\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 8392\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:09.871\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 134 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:09.876\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 47 semantic chunks from 134 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:09.877\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 8099\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:09.878\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 131 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:09.883\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 49 semantic chunks from 131 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:09.884\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 8417\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:09.885\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 138 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:09.891\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 46 semantic chunks from 138 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:09.891\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 8730\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:09.892\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 139 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:09.898\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 51 semantic chunks from 139 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:09.899\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 8921\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:09.900\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 143 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:09.906\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 56 semantic chunks from 143 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:09.907\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 8731\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:09.908\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 139 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:09.913\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 48 semantic chunks from 139 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:09.914\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 8614\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:09.915\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 138 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:09.921\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 46 semantic chunks from 138 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:09.921\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 8437\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:09.922\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 138 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:09.928\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 45 semantic chunks from 138 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:09.929\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 8279\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:09.930\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 138 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:09.936\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 50 semantic chunks from 138 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:09.937\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 8293\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:09.938\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 136 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:09.944\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 46 semantic chunks from 136 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:09.944\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 8881\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:09.945\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 142 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:09.952\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 50 semantic chunks from 142 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:09.953\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 8688\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:09.954\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 141 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:09.960\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 50 semantic chunks from 141 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:09.960\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 8555\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:09.961\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 137 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:09.968\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 50 semantic chunks from 137 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:09.968\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 8202\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:09.969\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 133 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:09.975\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 43 semantic chunks from 133 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:09.975\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 8335\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:09.976\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 131 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:09.982\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 49 semantic chunks from 131 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:09.982\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 8359\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:09.983\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 133 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:09.989\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 47 semantic chunks from 133 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:09.990\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 8346\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:09.991\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 138 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:09.997\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 45 semantic chunks from 138 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:09.998\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 8758\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:09.999\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 144 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:10.005\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 54 semantic chunks from 144 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:10.006\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 8634\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:10.007\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 140 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:10.013\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 49 semantic chunks from 140 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:10.013\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 9136\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:10.015\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 142 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:10.021\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 50 semantic chunks from 142 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:10.022\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 7556\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:10.023\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 124 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:10.028\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 42 semantic chunks from 124 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:10.029\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 6281\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:10.030\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 101 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:10.035\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 38 semantic chunks from 101 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:10.036\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 6594\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:10.037\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 101 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:10.043\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 40 semantic chunks from 101 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:10.043\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 6412\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:10.044\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 99 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:10.050\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 37 semantic chunks from 99 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:10.050\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 1147\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:10.051\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 19 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:10.053\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 6 semantic chunks from 19 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:10.053\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.refinery.overlap\u001B[0m:\u001B[36mrefine\u001B[0m:\u001B[36m456\u001B[0m - \u001B[34m\u001B[1mStarting overlap refinery for 1585 chunks with method=suffix, mode=token\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:10.073\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.refinery.overlap\u001B[0m:\u001B[36mrefine\u001B[0m:\u001B[36m481\u001B[0m - \u001B[1mOverlap refinement complete: added context to 1585 chunks\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:10.073\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.refinery.embedding\u001B[0m:\u001B[36mrefine\u001B[0m:\u001B[36m51\u001B[0m - \u001B[34m\u001B[1mStarting embedding refinery for 1585 chunks\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:10.131\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.refinery.embedding\u001B[0m:\u001B[36mrefine\u001B[0m:\u001B[36m56\u001B[0m - \u001B[1mEmbedding refinement complete: added embeddings to 1585 chunks\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:11.442\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.recursive\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m368\u001B[0m - \u001B[34m\u001B[1mStarting recursive chunking for text of length 172842\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:11.489\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.recursive\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m370\u001B[0m - \u001B[1mCreated 22 chunks using recursive chunking\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:11.489\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 7561\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:11.491\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 125 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:11.496\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 46 semantic chunks from 125 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:11.497\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 8255\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:11.498\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 130 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:11.503\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 38 semantic chunks from 130 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:11.504\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 8244\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:11.505\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 135 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:11.511\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 47 semantic chunks from 135 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:11.512\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 8611\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:11.513\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 137 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:11.518\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 50 semantic chunks from 137 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:11.519\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 8794\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:11.520\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 137 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:11.526\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 51 semantic chunks from 137 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:11.527\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 9159\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:11.528\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 148 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:11.534\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 55 semantic chunks from 148 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:11.534\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 8669\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:11.536\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 136 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:11.541\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 52 semantic chunks from 136 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:11.542\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 8159\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:11.543\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 131 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:11.548\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 53 semantic chunks from 131 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:11.549\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 8459\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:11.550\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 134 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:11.556\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 53 semantic chunks from 134 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:11.556\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 8903\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:11.557\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 139 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:11.564\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 53 semantic chunks from 139 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:11.564\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 8518\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:11.566\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 136 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:11.571\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 48 semantic chunks from 136 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:11.572\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 8142\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:11.573\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 134 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:11.579\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 44 semantic chunks from 134 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:11.580\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 5305\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:11.581\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 115 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:11.586\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 42 semantic chunks from 115 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:11.586\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 6306\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:11.587\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 124 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:11.592\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 36 semantic chunks from 124 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:11.592\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 9240\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:11.593\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 144 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:11.599\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 51 semantic chunks from 144 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:11.600\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 9105\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:11.601\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 147 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:11.607\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 53 semantic chunks from 147 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:11.607\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 7731\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:11.608\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 129 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:11.614\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 37 semantic chunks from 129 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:11.615\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 7293\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:11.616\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 128 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:11.621\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 38 semantic chunks from 128 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:11.622\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 6236\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:11.623\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 115 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:11.627\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 29 semantic chunks from 115 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:11.628\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 7329\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:11.629\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 122 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:11.634\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 46 semantic chunks from 122 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:11.634\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 8044\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:11.635\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 104 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:11.640\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 36 semantic chunks from 104 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:11.641\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 4779\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:11.642\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 63 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:11.645\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 22 semantic chunks from 63 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:11.645\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.refinery.overlap\u001B[0m:\u001B[36mrefine\u001B[0m:\u001B[36m456\u001B[0m - \u001B[34m\u001B[1mStarting overlap refinery for 980 chunks with method=suffix, mode=token\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:11.657\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.refinery.overlap\u001B[0m:\u001B[36mrefine\u001B[0m:\u001B[36m481\u001B[0m - \u001B[1mOverlap refinement complete: added context to 980 chunks\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:11.657\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.refinery.embedding\u001B[0m:\u001B[36mrefine\u001B[0m:\u001B[36m51\u001B[0m - \u001B[34m\u001B[1mStarting embedding refinery for 980 chunks\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:11.689\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.refinery.embedding\u001B[0m:\u001B[36mrefine\u001B[0m:\u001B[36m56\u001B[0m - \u001B[1mEmbedding refinement complete: added embeddings to 980 chunks\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:12.805\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.recursive\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m368\u001B[0m - \u001B[34m\u001B[1mStarting recursive chunking for text of length 159120\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:12.844\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.recursive\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m370\u001B[0m - \u001B[1mCreated 19 chunks using recursive chunking\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:12.845\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 8237\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:12.846\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 135 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:12.852\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 46 semantic chunks from 135 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:12.853\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 7962\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:12.854\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 129 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:12.860\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 47 semantic chunks from 129 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:12.860\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 8904\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:12.861\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 139 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:12.867\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 48 semantic chunks from 139 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:12.867\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 9347\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:12.868\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 144 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:12.874\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 51 semantic chunks from 144 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:12.875\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 8911\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:12.876\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 143 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:12.882\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 52 semantic chunks from 143 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:12.882\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 8641\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:12.883\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 139 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:12.890\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 52 semantic chunks from 139 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:12.890\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 8374\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:12.891\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 128 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:12.897\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 42 semantic chunks from 128 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:12.898\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 8730\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:12.899\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 140 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:12.904\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 44 semantic chunks from 140 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:12.905\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 8756\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:12.906\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 139 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:12.911\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 50 semantic chunks from 139 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:12.912\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 8751\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:12.913\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 147 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:12.919\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 53 semantic chunks from 147 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:12.920\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 9520\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:12.921\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 151 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:12.927\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 55 semantic chunks from 151 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:12.927\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 8998\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:12.928\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 146 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:12.934\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 51 semantic chunks from 146 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:12.936\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 8625\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:12.940\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 135 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:12.947\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 50 semantic chunks from 135 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:12.947\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 8383\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:12.948\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 133 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:12.954\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 50 semantic chunks from 133 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:12.955\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 8865\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:12.956\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 140 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:12.961\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 47 semantic chunks from 140 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:12.962\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 7771\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:12.963\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 127 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:12.969\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 45 semantic chunks from 127 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:12.969\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 6997\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:12.970\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 113 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:12.975\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 43 semantic chunks from 113 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:12.976\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 8903\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:12.977\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 134 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:12.982\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 48 semantic chunks from 134 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:12.983\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 4445\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:12.984\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 68 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:12.987\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 21 semantic chunks from 68 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:12.987\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.refinery.overlap\u001B[0m:\u001B[36mrefine\u001B[0m:\u001B[36m456\u001B[0m - \u001B[34m\u001B[1mStarting overlap refinery for 895 chunks with method=suffix, mode=token\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:12.998\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.refinery.overlap\u001B[0m:\u001B[36mrefine\u001B[0m:\u001B[36m481\u001B[0m - \u001B[1mOverlap refinement complete: added context to 895 chunks\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:12.999\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.refinery.embedding\u001B[0m:\u001B[36mrefine\u001B[0m:\u001B[36m51\u001B[0m - \u001B[34m\u001B[1mStarting embedding refinery for 895 chunks\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:13.026\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.refinery.embedding\u001B[0m:\u001B[36mrefine\u001B[0m:\u001B[36m56\u001B[0m - \u001B[1mEmbedding refinement complete: added embeddings to 895 chunks\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:13.550\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.recursive\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m368\u001B[0m - \u001B[34m\u001B[1mStarting recursive chunking for text of length 79244\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:13.571\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.recursive\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m370\u001B[0m - \u001B[1mCreated 10 chunks using recursive chunking\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:13.571\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 8031\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:13.572\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 133 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:13.578\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 50 semantic chunks from 133 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:13.579\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 8799\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:13.580\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 141 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:13.586\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 50 semantic chunks from 141 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:13.587\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 8635\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:13.588\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 137 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:13.594\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 50 semantic chunks from 137 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:13.594\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 8808\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:13.595\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 137 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:13.602\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 57 semantic chunks from 137 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:13.602\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 8471\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:13.603\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 137 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:13.609\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 51 semantic chunks from 137 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:13.610\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 8791\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:13.611\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 137 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:13.616\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 46 semantic chunks from 137 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:13.617\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 9061\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:13.618\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 136 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:13.624\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 50 semantic chunks from 136 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:13.624\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 9062\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:13.625\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 140 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:13.632\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 58 semantic chunks from 140 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:13.632\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 8817\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:13.633\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 135 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:13.639\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 54 semantic chunks from 135 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:13.639\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 769\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:13.640\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 14 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:13.641\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 3 semantic chunks from 14 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:13.641\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.refinery.overlap\u001B[0m:\u001B[36mrefine\u001B[0m:\u001B[36m456\u001B[0m - \u001B[34m\u001B[1mStarting overlap refinery for 469 chunks with method=suffix, mode=token\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:13.647\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.refinery.overlap\u001B[0m:\u001B[36mrefine\u001B[0m:\u001B[36m481\u001B[0m - \u001B[1mOverlap refinement complete: added context to 469 chunks\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:13.647\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.refinery.embedding\u001B[0m:\u001B[36mrefine\u001B[0m:\u001B[36m51\u001B[0m - \u001B[34m\u001B[1mStarting embedding refinery for 469 chunks\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:13.662\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.refinery.embedding\u001B[0m:\u001B[36mrefine\u001B[0m:\u001B[36m56\u001B[0m - \u001B[1mEmbedding refinement complete: added embeddings to 469 chunks\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:14.902\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.recursive\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m368\u001B[0m - \u001B[34m\u001B[1mStarting recursive chunking for text of length 192998\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:14.952\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.recursive\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m370\u001B[0m - \u001B[1mCreated 23 chunks using recursive chunking\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:14.952\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 8304\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:14.953\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 134 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:14.960\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 56 semantic chunks from 134 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:14.961\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 8566\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:14.962\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 139 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:14.967\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 54 semantic chunks from 139 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:14.968\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 8326\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:14.969\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 134 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:14.974\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 50 semantic chunks from 134 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:14.975\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 8761\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:14.976\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 137 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:14.981\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 51 semantic chunks from 137 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:14.982\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 7915\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:14.983\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 132 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:14.988\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 43 semantic chunks from 132 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:14.989\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 7826\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:14.990\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 128 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:14.996\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 46 semantic chunks from 128 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:14.997\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 8894\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:14.998\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 142 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:15.003\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 53 semantic chunks from 142 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:15.004\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 9135\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:15.005\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 146 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:15.011\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 50 semantic chunks from 146 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:15.011\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 8712\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:15.012\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 139 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:15.018\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 49 semantic chunks from 139 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:15.018\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 8624\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:15.019\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 139 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:15.025\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 45 semantic chunks from 139 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:15.026\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 8872\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:15.027\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 141 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:15.032\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 51 semantic chunks from 141 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:15.033\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 8725\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:15.034\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 145 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:15.039\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 51 semantic chunks from 145 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:15.040\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 8178\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:15.041\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 130 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:15.047\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 53 semantic chunks from 130 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:15.047\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 8588\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:15.048\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 137 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:15.054\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 51 semantic chunks from 137 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:15.054\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 8938\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:15.055\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 140 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:15.061\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 51 semantic chunks from 140 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:15.061\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 8954\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:15.062\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 136 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:15.068\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 49 semantic chunks from 136 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:15.068\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 9300\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:15.069\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 141 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:15.075\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 51 semantic chunks from 141 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:15.075\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 9281\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:15.076\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 141 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:15.083\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 51 semantic chunks from 141 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:15.083\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 9275\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:15.084\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 135 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:15.090\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 50 semantic chunks from 135 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:15.090\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 8733\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:15.091\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 138 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:15.098\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 55 semantic chunks from 138 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:15.098\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 9136\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:15.099\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 138 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:15.105\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 52 semantic chunks from 138 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:15.106\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 7491\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:15.107\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 201 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:15.113\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 67 semantic chunks from 201 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:15.114\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 2464\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:15.114\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 40 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:15.116\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 10 semantic chunks from 40 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:15.117\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.refinery.overlap\u001B[0m:\u001B[36mrefine\u001B[0m:\u001B[36m456\u001B[0m - \u001B[34m\u001B[1mStarting overlap refinery for 1139 chunks with method=suffix, mode=token\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:15.130\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.refinery.overlap\u001B[0m:\u001B[36mrefine\u001B[0m:\u001B[36m481\u001B[0m - \u001B[1mOverlap refinement complete: added context to 1139 chunks\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:15.131\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.refinery.embedding\u001B[0m:\u001B[36mrefine\u001B[0m:\u001B[36m51\u001B[0m - \u001B[34m\u001B[1mStarting embedding refinery for 1139 chunks\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:15.168\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.refinery.embedding\u001B[0m:\u001B[36mrefine\u001B[0m:\u001B[36m56\u001B[0m - \u001B[1mEmbedding refinement complete: added embeddings to 1139 chunks\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:16.146\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.recursive\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m368\u001B[0m - \u001B[34m\u001B[1mStarting recursive chunking for text of length 139417\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:16.181\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.recursive\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m370\u001B[0m - \u001B[1mCreated 17 chunks using recursive chunking\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:16.182\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 7632\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:16.183\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 133 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:16.190\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 41 semantic chunks from 133 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:16.190\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 8464\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:16.191\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 135 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:16.198\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 49 semantic chunks from 135 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:16.198\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 8917\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:16.199\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 140 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:16.205\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 51 semantic chunks from 140 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:16.206\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 9045\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:16.207\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 136 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:16.213\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 40 semantic chunks from 136 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:16.213\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 8920\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:16.214\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 135 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:16.221\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 46 semantic chunks from 135 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:16.221\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 8931\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:16.223\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 142 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:16.229\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 50 semantic chunks from 142 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:16.230\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 8848\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:16.231\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 139 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:16.237\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 50 semantic chunks from 139 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:16.237\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 8741\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:16.239\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 137 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:16.245\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 42 semantic chunks from 137 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:16.246\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 8837\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:16.247\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 141 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:16.253\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 46 semantic chunks from 141 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:16.253\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 8899\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:16.254\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 145 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:16.261\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 56 semantic chunks from 145 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:16.262\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 8483\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:16.263\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 138 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:16.269\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 45 semantic chunks from 138 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:16.270\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 8552\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:16.271\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 139 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:16.277\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 45 semantic chunks from 139 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:16.277\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 8983\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:16.278\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 144 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:16.285\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 46 semantic chunks from 144 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:16.285\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 8490\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:16.286\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 142 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:16.292\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 53 semantic chunks from 142 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:16.293\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 8187\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:16.294\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 129 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:16.299\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 38 semantic chunks from 129 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:16.300\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 9119\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:16.301\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 143 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:16.307\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 50 semantic chunks from 143 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:16.307\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 369\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:16.308\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 7 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:16.309\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 1 semantic chunks from 7 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:16.309\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.refinery.overlap\u001B[0m:\u001B[36mrefine\u001B[0m:\u001B[36m456\u001B[0m - \u001B[34m\u001B[1mStarting overlap refinery for 749 chunks with method=suffix, mode=token\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:16.319\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.refinery.overlap\u001B[0m:\u001B[36mrefine\u001B[0m:\u001B[36m481\u001B[0m - \u001B[1mOverlap refinement complete: added context to 749 chunks\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:16.319\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.refinery.embedding\u001B[0m:\u001B[36mrefine\u001B[0m:\u001B[36m51\u001B[0m - \u001B[34m\u001B[1mStarting embedding refinery for 749 chunks\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:16.343\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.refinery.embedding\u001B[0m:\u001B[36mrefine\u001B[0m:\u001B[36m56\u001B[0m - \u001B[1mEmbedding refinement complete: added embeddings to 749 chunks\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:16.552\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.recursive\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m368\u001B[0m - \u001B[34m\u001B[1mStarting recursive chunking for text of length 24464\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:16.558\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.recursive\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m370\u001B[0m - \u001B[1mCreated 3 chunks using recursive chunking\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:16.559\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 7912\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:16.560\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 125 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:16.566\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 46 semantic chunks from 125 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:16.567\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 8886\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:16.568\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 139 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:16.574\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 46 semantic chunks from 139 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:16.575\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 7666\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:16.576\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 124 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:16.581\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 46 semantic chunks from 124 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:16.582\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.refinery.overlap\u001B[0m:\u001B[36mrefine\u001B[0m:\u001B[36m456\u001B[0m - \u001B[34m\u001B[1mStarting overlap refinery for 138 chunks with method=suffix, mode=token\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:16.584\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.refinery.overlap\u001B[0m:\u001B[36mrefine\u001B[0m:\u001B[36m481\u001B[0m - \u001B[1mOverlap refinement complete: added context to 138 chunks\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:16.584\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.refinery.embedding\u001B[0m:\u001B[36mrefine\u001B[0m:\u001B[36m51\u001B[0m - \u001B[34m\u001B[1mStarting embedding refinery for 138 chunks\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:16.590\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.refinery.embedding\u001B[0m:\u001B[36mrefine\u001B[0m:\u001B[36m56\u001B[0m - \u001B[1mEmbedding refinement complete: added embeddings to 138 chunks\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:20.369\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.recursive\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m368\u001B[0m - \u001B[34m\u001B[1mStarting recursive chunking for text of length 548056\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:20.495\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.recursive\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m370\u001B[0m - \u001B[1mCreated 67 chunks using recursive chunking\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:20.495\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 7172\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:20.496\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 117 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:20.502\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 40 semantic chunks from 117 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:20.503\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 7358\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:20.504\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 120 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:20.510\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 40 semantic chunks from 120 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:20.510\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 7194\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:20.511\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 116 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:20.518\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 35 semantic chunks from 116 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:20.518\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 7873\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:20.519\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 123 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:20.525\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 37 semantic chunks from 123 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:20.525\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 8073\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:20.526\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 128 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:20.532\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 41 semantic chunks from 128 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:20.532\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 8273\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:20.533\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 128 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:20.539\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 40 semantic chunks from 128 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:20.540\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 8341\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:20.541\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 129 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:20.547\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 38 semantic chunks from 129 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:20.547\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 7943\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:20.548\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 124 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:20.554\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 41 semantic chunks from 124 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:20.554\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 8385\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:20.555\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 136 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:20.561\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 46 semantic chunks from 136 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:20.562\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 8196\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:20.563\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 132 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:20.568\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 36 semantic chunks from 132 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:20.568\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 8426\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:20.569\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 134 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:20.575\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 46 semantic chunks from 134 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:20.575\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 8374\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:20.577\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 134 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:20.582\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 40 semantic chunks from 134 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:20.582\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 8435\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:20.583\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 133 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:20.588\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 38 semantic chunks from 133 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:20.589\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 8172\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:20.590\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 132 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:20.596\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 39 semantic chunks from 132 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:20.597\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 8159\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:20.598\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 127 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:20.604\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 40 semantic chunks from 127 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:20.604\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 8149\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:20.605\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 129 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:20.611\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 43 semantic chunks from 129 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:20.612\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 7975\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:20.613\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 125 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:20.619\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 42 semantic chunks from 125 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:20.619\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 8579\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:20.620\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 129 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:20.626\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 48 semantic chunks from 129 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:20.626\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 8293\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:20.627\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 128 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:20.633\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 43 semantic chunks from 128 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:20.634\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 8075\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:20.635\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 128 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:20.640\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 42 semantic chunks from 128 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:20.640\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 8233\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:20.642\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 127 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:20.647\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 38 semantic chunks from 127 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:20.648\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 8543\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:20.649\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 138 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:20.655\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 42 semantic chunks from 138 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:20.655\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 7683\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:20.656\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 121 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:20.662\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 38 semantic chunks from 121 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:20.663\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 8293\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:20.664\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 132 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:20.669\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 49 semantic chunks from 132 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:20.670\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 8224\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:20.671\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 128 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:20.676\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 42 semantic chunks from 128 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:20.677\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 8200\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:20.678\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 127 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:20.683\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 46 semantic chunks from 127 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:20.684\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 8152\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:20.685\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 129 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:20.690\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 38 semantic chunks from 129 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:20.691\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 8372\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:20.692\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 132 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:20.698\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 41 semantic chunks from 132 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:20.699\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 8597\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:20.700\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 135 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:20.706\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 45 semantic chunks from 135 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:20.706\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 8346\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:20.707\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 132 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:20.713\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 35 semantic chunks from 132 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:20.713\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 8512\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:20.714\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 135 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:20.720\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 42 semantic chunks from 135 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:20.721\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 8415\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:20.722\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 132 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:20.728\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 42 semantic chunks from 132 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:20.728\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 8527\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:20.729\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 131 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:20.735\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 43 semantic chunks from 131 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:20.736\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 8608\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:20.737\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 128 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:20.743\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 38 semantic chunks from 128 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:20.743\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 8675\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:20.744\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 133 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:20.751\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 42 semantic chunks from 133 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:20.752\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 8470\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:20.753\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 135 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:20.759\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 40 semantic chunks from 135 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:20.759\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 8662\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:20.760\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 136 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:20.767\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 46 semantic chunks from 136 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:20.767\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 8299\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:20.768\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 129 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:20.774\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 42 semantic chunks from 129 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:20.774\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 8552\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:20.775\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 136 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:20.782\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 46 semantic chunks from 136 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:20.782\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 8202\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:20.783\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 134 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:20.789\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 43 semantic chunks from 134 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:20.789\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 8466\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:20.790\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 136 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:20.796\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 50 semantic chunks from 136 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:20.797\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 8459\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:20.798\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 130 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:20.804\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 44 semantic chunks from 130 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:20.805\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 8470\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:20.806\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 136 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:20.812\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 46 semantic chunks from 136 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:20.813\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 8600\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:20.814\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 135 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:20.820\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 47 semantic chunks from 135 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:20.820\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 8155\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:20.821\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 134 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:20.827\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 46 semantic chunks from 134 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:20.828\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 8007\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:20.829\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 122 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:20.835\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 44 semantic chunks from 122 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:20.835\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 8380\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:20.836\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 134 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:20.842\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 50 semantic chunks from 134 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:20.842\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 9273\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:20.843\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 148 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:20.849\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 47 semantic chunks from 148 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:20.850\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 8137\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:20.851\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 125 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:20.857\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 42 semantic chunks from 125 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:20.858\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 7887\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:20.859\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 129 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:20.865\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 44 semantic chunks from 129 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:20.866\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 8508\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:20.867\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 135 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:20.872\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 50 semantic chunks from 135 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:20.873\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 8377\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:20.874\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 132 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:20.879\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 47 semantic chunks from 132 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:20.880\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 8318\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:20.881\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 135 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:20.887\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 37 semantic chunks from 135 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:20.887\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 8350\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:20.888\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 137 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:20.894\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 41 semantic chunks from 137 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:20.895\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 8324\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:20.896\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 135 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:20.902\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 48 semantic chunks from 135 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:20.903\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 8146\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:20.904\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 128 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:20.910\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 41 semantic chunks from 128 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:20.911\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 8315\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:20.912\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 135 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:20.918\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 50 semantic chunks from 135 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:20.919\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 7162\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:20.920\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 124 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:20.925\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 43 semantic chunks from 124 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:20.926\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 6712\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:20.927\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 112 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:20.933\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 42 semantic chunks from 112 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:20.933\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 8444\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:20.934\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 124 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:20.940\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 38 semantic chunks from 124 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:20.940\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 8532\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:20.941\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 122 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:20.947\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 36 semantic chunks from 122 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:20.948\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 8440\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:20.949\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 126 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:20.955\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 42 semantic chunks from 126 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:20.955\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 7835\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:20.956\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 124 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:20.962\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 40 semantic chunks from 124 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:20.963\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 8454\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:20.964\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 119 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:20.970\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 30 semantic chunks from 119 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:20.970\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 8419\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:20.971\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 123 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:20.977\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 40 semantic chunks from 123 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:20.978\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 8308\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:20.979\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 119 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:20.985\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 34 semantic chunks from 119 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:20.985\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 4568\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:20.986\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 68 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:20.989\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 25 semantic chunks from 68 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:20.990\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.refinery.overlap\u001B[0m:\u001B[36mrefine\u001B[0m:\u001B[36m456\u001B[0m - \u001B[34m\u001B[1mStarting overlap refinery for 2797 chunks with method=suffix, mode=token\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:21.024\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.refinery.overlap\u001B[0m:\u001B[36mrefine\u001B[0m:\u001B[36m481\u001B[0m - \u001B[1mOverlap refinement complete: added context to 2797 chunks\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:21.025\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.refinery.embedding\u001B[0m:\u001B[36mrefine\u001B[0m:\u001B[36m51\u001B[0m - \u001B[34m\u001B[1mStarting embedding refinery for 2797 chunks\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:21.140\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.refinery.embedding\u001B[0m:\u001B[36mrefine\u001B[0m:\u001B[36m56\u001B[0m - \u001B[1mEmbedding refinement complete: added embeddings to 2797 chunks\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:23.282\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.recursive\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m368\u001B[0m - \u001B[34m\u001B[1mStarting recursive chunking for text of length 295777\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:23.355\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.recursive\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m370\u001B[0m - \u001B[1mCreated 35 chunks using recursive chunking\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:23.355\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 7705\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:23.356\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 128 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:23.363\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 46 semantic chunks from 128 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:23.364\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 8051\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:23.365\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 128 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:23.370\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 46 semantic chunks from 128 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:23.371\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 8719\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:23.372\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 141 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:23.378\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 53 semantic chunks from 141 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:23.379\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 9118\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:23.380\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 140 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:23.386\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 50 semantic chunks from 140 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:23.386\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 9256\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:23.387\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 145 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:23.393\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 56 semantic chunks from 145 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:23.393\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 8881\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:23.394\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 136 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:23.401\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 46 semantic chunks from 136 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:23.401\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 8949\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:23.402\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 139 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:23.409\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 48 semantic chunks from 139 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:23.409\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 8763\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:23.410\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 139 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:23.416\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 45 semantic chunks from 139 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:23.417\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 8877\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:23.418\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 135 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:23.423\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 47 semantic chunks from 135 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:23.424\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 9191\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:23.425\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 143 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:23.431\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 45 semantic chunks from 143 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:23.432\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 8983\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:23.433\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 140 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:23.438\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 47 semantic chunks from 140 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:23.439\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 8578\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:23.440\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 140 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:23.446\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 50 semantic chunks from 140 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:23.446\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 7948\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:23.447\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 135 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:23.453\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 42 semantic chunks from 135 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:23.453\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 7931\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:23.454\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 124 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:23.460\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 39 semantic chunks from 124 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:23.461\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 8810\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:23.462\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 136 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:23.468\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 54 semantic chunks from 136 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:23.468\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 8993\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:23.469\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 143 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:23.476\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 51 semantic chunks from 143 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:23.476\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 8559\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:23.477\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 133 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:23.484\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 44 semantic chunks from 133 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:23.484\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 8122\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:23.485\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 133 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:23.492\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 43 semantic chunks from 133 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:23.492\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 8290\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:23.493\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 134 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:23.499\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 52 semantic chunks from 134 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:23.500\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 8219\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:23.501\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 135 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:23.506\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 47 semantic chunks from 135 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:23.507\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 8505\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:23.508\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 145 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:23.515\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 54 semantic chunks from 145 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:23.515\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 8496\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:23.516\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 136 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:23.522\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 46 semantic chunks from 136 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:23.523\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 7754\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:23.524\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 131 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:23.529\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 46 semantic chunks from 131 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:23.530\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 8623\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:23.531\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 144 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:23.537\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 52 semantic chunks from 144 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:23.537\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 8255\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:23.538\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 133 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:23.545\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 48 semantic chunks from 133 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:23.545\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 8170\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:23.546\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 131 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:23.552\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 42 semantic chunks from 131 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:23.552\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 7914\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:23.553\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 126 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:23.559\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 43 semantic chunks from 126 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:23.560\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 7895\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:23.561\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 132 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:23.567\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 40 semantic chunks from 132 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:23.568\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 8173\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:23.569\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 131 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:23.575\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 51 semantic chunks from 131 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:23.576\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 8983\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:23.577\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 135 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:23.583\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 46 semantic chunks from 135 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:23.583\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 8829\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:23.584\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 130 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:23.590\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 51 semantic chunks from 130 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:23.591\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 8762\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:23.592\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 139 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:23.598\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 50 semantic chunks from 139 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:23.598\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 8784\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:23.599\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 131 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:23.605\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 42 semantic chunks from 131 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:23.605\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 8733\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:23.606\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 129 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:23.613\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 34 semantic chunks from 129 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:23.613\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m531\u001B[0m - \u001B[34m\u001B[1mStarting semantic chunking for text of length 5958\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:23.614\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m535\u001B[0m - \u001B[34m\u001B[1mPrepared 118 sentences for semantic analysis\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:23.620\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.chunker.semantic\u001B[0m:\u001B[36mchunk\u001B[0m:\u001B[36m573\u001B[0m - \u001B[1mCreated 38 semantic chunks from 118 sentences\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:23.620\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.refinery.overlap\u001B[0m:\u001B[36mrefine\u001B[0m:\u001B[36m456\u001B[0m - \u001B[34m\u001B[1mStarting overlap refinery for 1634 chunks with method=suffix, mode=token\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:23.640\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.refinery.overlap\u001B[0m:\u001B[36mrefine\u001B[0m:\u001B[36m481\u001B[0m - \u001B[1mOverlap refinement complete: added context to 1634 chunks\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:23.641\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mchonkie.refinery.embedding\u001B[0m:\u001B[36mrefine\u001B[0m:\u001B[36m51\u001B[0m - \u001B[34m\u001B[1mStarting embedding refinery for 1634 chunks\u001B[0m\n",
      "\u001B[32m2025-11-09 20:17:23.701\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mchonkie.refinery.embedding\u001B[0m:\u001B[36mrefine\u001B[0m:\u001B[36m56\u001B[0m - \u001B[1mEmbedding refinement complete: added embeddings to 1634 chunks\u001B[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "This can be made even faster with chonie pipelines where you can pass a bunch of texts together and chunk all docs in batches first and push them to db. Checkout https://docs.chonkie.ai/oss/pipelines",
   "id": "1b10483bbc38d514"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Cool, let's search through these contents",
   "id": "4bb7c97365d21379"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-09T09:18:49.864077Z",
     "start_time": "2025-11-09T09:18:49.861098Z"
    }
   },
   "cell_type": "code",
   "source": "content = db.table('content') # can also use db.t.content",
   "id": "d7ca58f509606121",
   "outputs": [],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-09T09:19:38.385906Z",
     "start_time": "2025-11-09T09:19:38.383195Z"
    }
   },
   "cell_type": "code",
   "source": "fts_search = bind(content.search, order_by='rank', columns=['id','content', 'metadata'], limit=50)",
   "id": "3dc042d54229c2fd",
   "outputs": [],
   "execution_count": 18
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-09T09:19:39.000105Z",
     "start_time": "2025-11-09T09:19:38.997929Z"
    }
   },
   "cell_type": "code",
   "source": "q = 'economic growth in Europe'",
   "id": "e8aaf0c3f8db4242",
   "outputs": [],
   "execution_count": 19
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-09T09:19:39.563281Z",
     "start_time": "2025-11-09T09:19:39.558998Z"
    }
   },
   "cell_type": "code",
   "source": [
    "fts_r = [r for r in fts_search(q)] # FTS search\n",
    "print(len(fts_r), 'results got')"
   ],
   "id": "291ace0fef6d5097",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 results got\n"
     ]
    }
   ],
   "execution_count": 20
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "As you can see, there is no exact term `economic growth in Europe` anywhere in the texts. Let's make the search wide. FTS allows globs like * and use OR. There is so much you can tune with apsw fts. We provide strong defaults (always customisable) with the `pre` function.",
   "id": "39cf035081c6d0b7"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-09T09:21:23.452017Z",
     "start_time": "2025-11-09T09:21:23.112476Z"
    }
   },
   "cell_type": "code",
   "source": [
    "fts_r = dict2obj(L(fts_search(pre(q))))\n",
    "print(len(fts_r), 'results got')"
   ],
   "id": "2227c2b6109906a4",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50 results got\n"
     ]
    }
   ],
   "execution_count": 21
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "This is just scratching the surface, apsw puts fts on steroids. Look forward for more updates to litesearch along these lines. To know more about apsw fts, refer: https://rogerbinns.github.io/apsw/example-fts.html",
   "id": "23760d6d84b5ea54"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Okay, We've got some results. Let's get some vec search results.",
   "id": "b7878bae29f3d1a8"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-09T09:22:04.479665Z",
     "start_time": "2025-11-09T09:22:04.477157Z"
    }
   },
   "cell_type": "code",
   "source": "from chonkie import AutoEmbeddings",
   "id": "97a7b9d74ecf7409",
   "outputs": [],
   "execution_count": 22
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Chonkie exposes model2vec embeddings which are static embeddings. Static embeddings are 500 times smaller and 50 times faster with a very small performance loss. Potion-retrieval-32M is a good model imo. Learn more at: https://github.com/MinishLab/model2vec",
   "id": "f3a8aeb5f2f9bc13"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-09T09:22:08.664656Z",
     "start_time": "2025-11-09T09:22:07.251776Z"
    }
   },
   "cell_type": "code",
   "source": "embedding_fn = AutoEmbeddings().get_embeddings('minishlab/potion-retrieval-32M').embed",
   "id": "50f03d675c62a101",
   "outputs": [],
   "execution_count": 23
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-09T09:22:37.237121Z",
     "start_time": "2025-11-09T09:22:37.022945Z"
    }
   },
   "cell_type": "code",
   "source": [
    "vec_r = L(dict2obj(content(select='id, content, metadata', where='embedding is not null', where_args=dict(qvec=embedding_fn(q).tobytes()), order_by='distance_cosine_f32(embedding, :qvec)',limit=50)))\n",
    "print(len(fts_r), 'results got')"
   ],
   "id": "f37b85c84b7eb97a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50 results got\n"
     ]
    }
   ],
   "execution_count": 25
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Cool, we see results. Now, these are ways to get these results separately. The underlying fastlite and apswutils wrappers over sqlite are powerful and allow you to manipulate the db in efficient ways. Checkout: https://github.com/AnswerDotAI/fastlite and https://github.com/AnswerDotAI/apswutils/tree/main",
   "id": "c1e273738bb7a0ec"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "#### litesearch provides a search method which reranks the results from both FTS and vector search using Reciprocal Rank Fusion (RRF)\n",
    "> You can always turn it off."
   ],
   "id": "628498d5a7bec5c"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-09T09:23:27.744543Z",
     "start_time": "2025-11-09T09:23:27.614135Z"
    }
   },
   "cell_type": "code",
   "source": "res=db.search(pre(q), embedding_fn(q).tobytes(), columns=['id', 'content', 'metadata'], rrf=True)",
   "id": "231ab806887ee8c6",
   "outputs": [],
   "execution_count": 26
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-09T09:30:37.842494Z",
     "start_time": "2025-11-09T09:30:37.841006Z"
    }
   },
   "cell_type": "code",
   "source": "print(first(res))",
   "id": "a445dbcc37aecba5",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'id': 28599, 'content': 'Property Rights (IPR) appli\\xad\\ncations \\nInnovations - \\nNumber of innovations \\nresulting from the projects \\nfunded by the Programme \\n(by type of innovation) \\nincluding from awarded IPRs \\nEconomic growth - \\nCreation, growth & market \\n', 'metadata': '{\"tokens\": 79, \"start_index\": 189182, \"end_index\": 189366, \"context\": \"Economic growth - \\\\nCreation, growth & market \\\\n\", \"name\": \"CL2021R0695EN0010010.0001.3bi_cp 1..1\", \"path\": null, \"format\": \"PDF 1.7\", \"title\": \" Regulation (EU) 2021/695 of the European Parliament and of the Council of 28\\xa0April 2021 establishing Horizon Europe  the Framework Programme for Research and Innovation\", \"author\": \"Publications Office\", \"subject\": \" \", \"keywords\": \"\", \"creator\": \"Arbortext Advanced Print Publisher 10.0.1465/W Unicode\", \"producer\": \"3-Heights(TM) PDF to PDF-A Converter Shell 4.7.24.2 (http://www.pdf-tools.com)\", \"creationDate\": \"D:20240320171849+05\\'00\\'\", \"modDate\": \"D:20240326180552+01\\'00\\'\", \"trapped\": \"\", \"encryption\": null}'}\n"
     ]
    }
   ],
   "execution_count": 36
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "You do not need to, but you can now flashrank these results if needed. The Potion-retrieval model is a bge distilled model which is a fusion cross encoder with strong retrieval capabilities.",
   "id": "ba65569e0bb66a7b"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-09T09:24:04.724340Z",
     "start_time": "2025-11-09T09:24:04.663637Z"
    }
   },
   "cell_type": "code",
   "source": "from flashrank import Ranker, RerankRequest",
   "id": "64f13c1b75251eb7",
   "outputs": [],
   "execution_count": 28
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "It's a good idea to understand what the mak token limit is for the documents in the db so that we can set the max length of the ranker accordingly. If you set a high amount, it does affect performance.So, the ideal is to set it to max tokens + 100-200",
   "id": "2e12a74b91373dde"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-09T09:26:21.020502Z",
     "start_time": "2025-11-09T09:26:20.927091Z"
    }
   },
   "cell_type": "code",
   "source": "max_token = int(db.q(\"select max(json_extract(metadata, '$.tokens')) as m from content\")[0]['m'])",
   "id": "7858b334f6deac95",
   "outputs": [],
   "execution_count": 30
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-09T09:27:45.507009Z",
     "start_time": "2025-11-09T09:27:45.448861Z"
    }
   },
   "cell_type": "code",
   "source": "ranker = Ranker(max_length=max_token+150)",
   "id": "19161c1181a20c0",
   "outputs": [],
   "execution_count": 31
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-09T09:28:37.997453Z",
     "start_time": "2025-11-09T09:28:37.953400Z"
    }
   },
   "cell_type": "code",
   "source": "res1=ranker.rerank(RerankRequest(q, res.map(lambda r: dict(text=r.content, id=r.id))))",
   "id": "7a5e6f6b8292d543",
   "outputs": [],
   "execution_count": 33
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-09T09:31:09.677068Z",
     "start_time": "2025-11-09T09:31:09.675394Z"
    }
   },
   "cell_type": "code",
   "source": "print(first(res1))",
   "id": "12cbd222d681d5b1",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'text': \"\\nTo address future societal challenges, embrace the opportunities of new tech\\xad\\nnologies and contribute to environmentally friendly and sustainable economic \\ngrowth, jobs, competitiveness and the well-being of Europe's citizens, there is \\nthe need to further strengthen Europe's capacity to innovate by: strengthening \\n\", 'id': 28340, 'score': np.float32(0.99480695)}\n"
     ]
    }
   ],
   "execution_count": 37
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Now, let's compare flashrank results and litesearch rerank results.",
   "id": "567a27350f67974f"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-09T09:28:45.658820Z",
     "start_time": "2025-11-09T09:28:45.654363Z"
    }
   },
   "cell_type": "code",
   "source": "[print(r1['id'], r2['id']) for r1,r2 in zip(res,res1)]",
   "id": "114e7e08e4892ffb",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28599 28340\n",
      "25833 25394\n",
      "25834 25163\n",
      "25335 26874\n",
      "25163 25834\n",
      "28600 25829\n",
      "25393 28263\n",
      "28282 28600\n",
      "25394 26895\n",
      "25173 28262\n",
      "28595 25170\n",
      "25164 24751\n",
      "25829 25173\n",
      "26175 26718\n",
      "25336 23607\n",
      "28283 27144\n",
      "25821 23218\n",
      "28340 25336\n",
      "27813 25164\n",
      "25169 21238\n",
      "23607 25315\n",
      "26874 23605\n",
      "25170 28599\n",
      "24751 24528\n",
      "28477 23613\n",
      "26905 28282\n",
      "28262 25821\n",
      "26873 27813\n",
      "25737 22904\n",
      "28376 25833\n",
      "5785 25738\n",
      "25738 28595\n",
      "9283 26189\n",
      "28597 13644\n",
      "26853 29289\n",
      "5971 28215\n",
      "28263 10742\n",
      "21165 1302\n",
      "5972 25335\n",
      "21164 28214\n",
      "9435 25169\n",
      "28478 28283\n",
      "26906 10741\n",
      "13906 1939\n",
      "28598 25393\n",
      "32650 24473\n",
      "26884 24276\n",
      "1538 26894\n",
      "26854 26906\n",
      "25315 26151\n",
      "27144 26175\n",
      "26895 28478\n",
      "10742 25737\n",
      "13644 26853\n",
      "10741 27737\n",
      "21238 28477\n",
      "29289 23287\n",
      "24473 25775\n",
      "26151 23608\n",
      "27737 23311\n",
      "1939 22965\n",
      "24276 26854\n",
      "22904 28598\n",
      "23613 30101\n",
      "26894 1538\n",
      "23311 26905\n",
      "23608 26884\n",
      "23605 15307\n",
      "25775 31871\n",
      "1302 26873\n",
      "30101 5785\n",
      "23287 27193\n",
      "27193 28597\n",
      "28215 21165\n",
      "31871 9435\n",
      "10797 10208\n",
      "26718 5972\n",
      "15307 9283\n",
      "23218 10797\n",
      "10208 32650\n",
      "24528 31870\n",
      "31870 5971\n",
      "28214 28376\n",
      "22965 13906\n",
      "26189 21164\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 35
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "So you have it. a simple rag pipeline.",
   "id": "a8028b71e4f94f08"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
